{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation of database file and connection etc, imports\n",
    "import sqlite3\n",
    "import requests, json\n",
    "from requests import ConnectionError\n",
    "import itertools, time\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from subprocess import Popen, PIPE\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from math import log10\n",
    "from gprofiler import GProfiler\n",
    "from upsetplot import from_contents\n",
    "from upsetplot import plot as uplot\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from scipy.stats import mannwhitneyu\n",
    "import colorsys\n",
    "db = sqlite3.connect('./finalDupCompDatabase')\n",
    "db.isolation_level = None\n",
    "cursor = db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ohnolog dataset generation from macrosynteny segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of segment coordinates to obtain gene lists with current assembly (lifting GrCH37 to 38) and nc genes\n",
    "segCoordDict38 = {}\n",
    "segGenesAll = {}\n",
    "segGenesProt = {}\n",
    "excludedGenes = []\n",
    "with open('segments/map/HUMAN.txt') as file:\n",
    "    for line in tqdm(file):\n",
    "        line = line.strip('\\n').split('\\t')\n",
    "        seg, chrom, s37, e37 = line\n",
    "        print(seg)\n",
    "        print('Converting to GrCh38...')\n",
    "        #convert to GrCh38\n",
    "        headers = {'Content-Type':'application/json'}\n",
    "        query1 = \"http://rest.ensembl.org/map/human/GRCh37/\"+chrom +\":\"+ s37 + \"..\" + e37 + \":1/GRCh38?\"\n",
    "        r = requests.get(query1, headers=headers)\n",
    "       # qs += 1\n",
    "        \n",
    "        outputMap = r.json()['mappings']\n",
    "        outputMap.sort(key= lambda x: x['mapped']['start']) #fairly sure the segs are in order already but anyways\n",
    "        #set start as start of first mapped region, end as end of last mapped region, should work for single mappings too\n",
    "        s = outputMap[0]['mapped']['start']\n",
    "        e = outputMap[-1]['mapped']['end']\n",
    "        segCoordDict38[seg] = (chrom,s,e)\n",
    "        #check if we're over the length filter and divide ino chunks\n",
    "        if int(e)-int(s) > 500000:\n",
    "            geneOutput = []\n",
    "            nextStart = int(s)\n",
    "            nextEnd = int(s) + 500000\n",
    "            while nextEnd < int(e):\n",
    "#                 print('dividing')\n",
    "#                 print(nextStart,nextEnd)\n",
    "                query = \"http://rest.ensembl.org/overlap/region/human/\"+ chrom + \":\" + str(nextStart) + \"-\" + str(nextEnd) + \"?feature=gene\"\n",
    "                r = requests.get(query, headers=headers)\n",
    "                #qs += 1\n",
    "                geneOutput.extend(r.json())\n",
    "                nextStart = nextEnd+1\n",
    "                nextEnd = nextStart + 500000 #move on to next subsegment\n",
    "            else:\n",
    "                query = \"http://rest.ensembl.org/overlap/region/human/\"+ chrom + \":\" + str(nextStart) + \"-\" + str(e) + \"?feature=gene\"\n",
    "                r = requests.get(query, headers=headers)\n",
    "                #qs += 1\n",
    "                geneOutput.extend(r.json())\n",
    "        else:\n",
    "            query = \"http://rest.ensembl.org/overlap/region/human/\"+ chrom + \":\" + str(s) + \"-\" + str(e) + \"?feature=gene\"\n",
    "            r = requests.get(query, headers=headers)\n",
    "            #qs +=1\n",
    "            geneOutput = r.json()\n",
    "        #make sure output is ordered by coordinates\n",
    "        geneOutput.sort(key= lambda x: min([x['start'],x['end']]))\n",
    "        protGenes = []\n",
    "        allGenes = []\n",
    "        lastEnd = 0\n",
    "        lastStrand = ''\n",
    "        doneList = [] #for duplicate entries, prob coming from spanning two chunks\n",
    "        print('Moved on to filtering genes...')\n",
    "        for pos,gene in enumerate(geneOutput):\n",
    "            if gene['id'] in doneList:\n",
    "                continue\n",
    "            s,e,strand = gene['start'],gene['end'],gene['strand']\n",
    "            if strand == lastStrand: #check for overlaps if on the same strand\n",
    "                try:\n",
    "                    nextStart = geneOutput[pos+1]['start']\n",
    "                #intronic/other sitch where it's fully inside another gene?\n",
    "                    if s <= lastEnd and e<= lastEnd: #current gene is entirely within the last one\n",
    "                        excludedGenes.append(gene['id'])\n",
    "                        lastEnd = e\n",
    "                        lastStrand = strand\n",
    "                #readthrough\n",
    "                    elif s <= lastEnd and e >= nextStart: #current gene overlaps last and next gene\n",
    "                        excludedGenes.append(gene['id'])\n",
    "                        lastEnd = e\n",
    "                        lastStrand = strand\n",
    "                    else:\n",
    "                        if gene['biotype'] == 'protein_coding':\n",
    "                            protGenes.append(gene['id'])\n",
    "                            allGenes.append(gene['id'])\n",
    "                        else:\n",
    "                            allGenes.append(gene['id'])\n",
    "                        lastEnd = e\n",
    "                        lastStrand = strand\n",
    "                except IndexError: #last gene, intron check only\n",
    "                    if s <= lastEnd and e <= lastEnd:\n",
    "                        excludedGenes.append(gene['id'])\n",
    "                        lastEnd = e\n",
    "                        lastStrand = strand\n",
    "                    else:\n",
    "                        if gene['biotype'] == 'protein_coding':\n",
    "                            protGenes.append(gene['id'])\n",
    "                            allGenes.append(gene['id'])\n",
    "                        else:\n",
    "                            allGenes.append(gene['id'])\n",
    "                        lastEnd = e\n",
    "                        lastStrand = strand\n",
    "            else: #last gene was on the other strand, we don't need to worry about overlaps\n",
    "                if gene['biotype'] == 'protein_coding':\n",
    "                    protGenes.append(gene['id'])\n",
    "                    allGenes.append(gene['id'])\n",
    "                else:\n",
    "                    allGenes.append(gene['id'])\n",
    "                \n",
    "                lastEnd = e\n",
    "                lastStrand = strand\n",
    "            doneList.append(gene['id'])\n",
    "        #I don't particularly think this is necessary but I must have been using set for a reason???\n",
    "        segGenesAll[seg] = []\n",
    "        segGenesProt[seg] = []\n",
    "        for gene in allGenes:\n",
    "            if gene not in segGenesAll[seg]:\n",
    "                segGenesAll[seg].append(gene)\n",
    "        for gene in protGenes:\n",
    "            if gene not in segGenesProt[seg]:\n",
    "                segGenesProt[seg].append(gene)\n",
    "#         segGenesAll[seg] = list(set(allGenes))\n",
    "#         segGenesProt[seg] = list(set(protGenes)) #we're NOT going to call set and ruin all the effort of getting the order right\n",
    "\n",
    "with open('genesInSeg_all.txt','w') as file:\n",
    "    for seg in segGenesAll:\n",
    "        line = seg + '\\t' + ','.join(segGenesAll[seg]) + '\\n'\n",
    "        file.write(line)\n",
    "with open('genesInSeg_coding.txt','w') as file:\n",
    "    for seg in segGenesProt:\n",
    "        line = seg + '\\t' + ','.join(segGenesProt[seg]) + '\\n'\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ohnolog assignment\n",
    "t = time.time()\n",
    "print('Putting together input segments')\n",
    "segGenes = {}\n",
    "with open('genesInSeg_coding_fixed_readthroughs.txt','r') as file:\n",
    "    for line in file:\n",
    "        line = line.strip('\\n').split('\\t')\n",
    "        segGenes[line[0]] = line[1].split(',')\n",
    "# #create list of all included genes because I have a feeling the paralogs file included nc genes\n",
    "incGenes = []\n",
    "for seg in segGenes:\n",
    "    incGenes.extend(segGenes[seg])\n",
    "# #if synteny is reversed for any reason (eg inversion) then ohnologs can be missed, add in reversal of each segment\n",
    "orSegs = [x for x in segGenes.keys()]\n",
    "for seg in orSegs:\n",
    "    revList = segGenes[seg][::-1]\n",
    "    segGenes[seg+'R'] = revList\n",
    "def convert_prot_gene(prot_ID):\n",
    "    import time, requests, json\n",
    "#     t = time.time()\n",
    "    headers = {'Content-Type':'application/json'}\n",
    "    url = 'http://rest.ensembl.org/lookup/' + prot_ID + '?'\n",
    "    r = requests.get(url, headers = headers)\n",
    "    if 'error' in r.json().keys(): #prot id not found\n",
    "        raise ValueError('id deprecated')\n",
    "    transID = r.json()['Parent']\n",
    "    \n",
    "    url = 'http://rest.ensembl.org/lookup/' + transID + '?'\n",
    "    r = requests.get(url, headers = headers)\n",
    "    geneID = r.json()['Parent']\n",
    "\n",
    "    return geneID\n",
    "def get_segment(gene_id):\n",
    "    if 'ENSP' in gene_id: #id is actually a prot id\n",
    "        gene_id = convert_prot_gene(gene_id)\n",
    "    try:\n",
    "        loc = [seg for seg in segGenes if gene_id in segGenes[seg]]\n",
    "    except IndexError:\n",
    "        loc = None\n",
    "    return loc\n",
    "\n",
    "paralogs = []\n",
    "with open('ensemblParalogsv99.txt','r') as file:\n",
    "    file.readline() #header\n",
    "    for line in file:\n",
    "        line = line.strip('\\n').split('\\t')\n",
    "        if line[0] != '' and line[1] != '' and line[0] in incGenes and line[1] in incGenes:\n",
    "            paralogs.append((line[0],line[1]))\n",
    "possOhnos = []\n",
    "segCount = 0\n",
    "# gapAllowed = 5\n",
    "lastGene = ''\n",
    "print('Prep done, let\\'s go!')\n",
    "print('Prep took:', round(time.time()-t,2), 'seconds!')\n",
    "\n",
    "#iterate over genes in segments\n",
    "t = time.time()\n",
    "for gapAllowed in [8,10]:\n",
    "    minBlockSize = 3\n",
    "    possOhnos = []\n",
    "    for seg in segGenes:\n",
    "    #     seg = 'Human_4'\n",
    "        #no need to iterate over the reversed segments, they just need to be queried\n",
    "        if 'R' in seg:\n",
    "            continue\n",
    "        print(seg)\n",
    "        geneList = segGenes[seg]\n",
    "        geneCount = 0\n",
    "    #     geneList = seg1\n",
    "        for gene in tqdm(geneList):\n",
    "            pairsList = [x for x in paralogs if gene in x]\n",
    "            #if it's a singleton, continue\n",
    "            if len(pairsList) == 0:\n",
    "                geneCount += 1\n",
    "                continue\n",
    "            else: #has paralogs\n",
    "                paras = []\n",
    "                for pair in pairsList: #append the paralog out of each pair\n",
    "                    if pair[0] == gene:\n",
    "                        paras.append(pair[1])\n",
    "                    elif pair[1] == gene:\n",
    "                        paras.append(pair[0])\n",
    "            for para in set(paras): #can't be bothered checking if paralog pairs are reciprocal, prob are but just in case\n",
    "                if para == '': #deal with empty strings from (I think) trailing commas with .split()\n",
    "                    continue\n",
    "                added = False\n",
    "                #print('paralog:',para)\n",
    "                blockBroken = False\n",
    "                blockSize = 0\n",
    "                #find segments the paralogs are on\n",
    "                segList = get_segment(para) #adjusted to return seg and it's reverse\n",
    "                #print(segList)\n",
    "                if segList: #if the paralog is in a segment\n",
    "                    for seg2 in segList:\n",
    "                        if seg2 != seg and seg2 != seg+'R': #paralog in segment and it's not this one or it's reversal\n",
    "\n",
    "                            #fetch the location of this paralog in its own segment\n",
    "            #                 seg2 = get_segment(para)\n",
    "                            pos = segGenes[seg2].index(para)\n",
    "\n",
    "                            #look at genes either side of this focal pair in the two segments\n",
    "                            #left search\n",
    "                            order1 = 1 #vars defining where we are in the current search: starts one above or below focal position\n",
    "                            order2 = 1\n",
    "                            noMatch1 = 0 #vars tracking size of gap currently open in each seg\n",
    "                            noMatch2 = 0\n",
    "\n",
    "                             #start a new synteny block\n",
    "                            blockBroken = False\n",
    "                            #vars for tracking the size of the current block to see if it meets minimum before it breaks\n",
    "                            currentPairs = [[gene,para]]\n",
    "                            currentMatches = 1 #not the same as number of pairs because one focal to two para (tandem dup) is only 1 syntenic match really\n",
    "\n",
    "                            while blockBroken == False:\n",
    "                                #catch index errors from segment ends\n",
    "                                if geneCount - order1 < 0: #focal seg left side exhausted, break\n",
    "            #                         print('went off left end of focal seg: broke')\n",
    "                                    if currentMatches >= minBlockSize:\n",
    "                                        possOhnos.extend(currentPairs)\n",
    "                                    break\n",
    "                            \n",
    "                                elif pos - order2 < 0 and noMatch1 == gapAllowed: #para seg left end reached, no more focal genes left to test\n",
    "            #                         print('went off left end and no focal genes left:broke')\n",
    "                                    if currentMatches >= minBlockSize:\n",
    "                                        possOhnos.extend(currentPairs)\n",
    "                                    break\n",
    "                                elif pos - order2 < 0 and noMatch2 == 0: #the last gene was an ohnolog, so we'd have to move on to the next para gene, which doesn't exist\n",
    "            #                         print(\"we've run out of para seg, last gene was an ohnolog\")\n",
    "                                    if currentMatches >= minBlockSize:\n",
    "                                        possOhnos.extend(currentPairs)\n",
    "\n",
    "                                    break\n",
    "                                elif pos - order2 < 0: #if more focal genes to test, skip to the next one that doesn't have a match\n",
    "            #                         print('went off left end and there were more focal genes: continue')\n",
    "                                    order1 += 1\n",
    "                                    order2 = 1\n",
    "                                    noMatch2 = 0\n",
    "                                    noMatch1 += 1\n",
    "                                    continue\n",
    "                                else: #define the test genes if no edge case issues to be dealt with\n",
    "                                    testGene1 = segGenes[seg][geneCount-order1]\n",
    "                                    testGene2 = segGenes[seg2][pos-order2]\n",
    "                                #trying to catch post-WGD tandem duplication, could otherwise create an artificial gap\n",
    "                                #should only come into play if last gene was classed an ohnolog, lastGene should otherwise be ''\n",
    "                                #if it is a paralog of the last gene then add the pair to the ohno list and increment the para position\n",
    "                                if (lastGene, testGene2) in paralogs or (testGene2, lastGene) in paralogs:\n",
    "                                    #is this a post or pre WGD tandem duplication?\n",
    "                                    #case where there's a sort of square relationship set between 4 genes\n",
    "                                    if (testGene1, testGene2) in paralogs or (testGene2, testGene1) in paralogs: #also a paralog of the current test gene, possibly a pre-WGD dup\n",
    "                                        currentPairs.append([testGene1,testGene2])\n",
    "                                        currentMatches += 1\n",
    "                                        #move on to next pair, current focal test becomes 'lastGene' in testing for tandems\n",
    "                                        order1 += 1\n",
    "                                        order2 += 1\n",
    "                                        noMatch1 = 0\n",
    "                                        noMatch2 = 0\n",
    "                                        lastGene = testGene1\n",
    "                                        continue\n",
    "                                    else:\n",
    "                                        currentPairs.append([lastGene,testGene2])\n",
    "                                        #no increment, this isn't a new match, it's a post-WGD duplication\n",
    "                                        order2 +=1\n",
    "                                        noMatch1 = 0\n",
    "                                        noMatch2 = 0\n",
    "                                        #move on to next para seg gene, lastGene remains the same as we assume a post-WGD tandem in para seg\n",
    "                                        continue\n",
    "                                #if there were tandems detected the loop won't reach this point: these are more straightforward\n",
    "                                if (testGene1,testGene2) in paralogs or (testGene2,testGene1) in paralogs:\n",
    "                                    #add to table, ohnolog pair\n",
    "                                    currentPairs.append([testGene1,testGene2])\n",
    "                                    currentMatches += 1\n",
    "                                    order1 += 1\n",
    "                                    order2 += 1\n",
    "                                    noMatch1 = 0\n",
    "                                    noMatch2 = 0\n",
    "                                    #store current gene to test for paralogy in next loop so I don't have to do the edge handling twice\n",
    "                                    lastGene = testGene1\n",
    "\n",
    "                                    #maybe keep track of pairs added to avoid redundancy? Has to be a way not to re-hash the same regions over and over\n",
    "                                else:\n",
    "                                    noMatch2 += 1\n",
    "                                    order2 += 1\n",
    "                                    lastGene = '' #only look at expanding a tandem block if the last focal gene was an ohnolog\n",
    "                                if noMatch2 >= gapAllowed + 1: #gap of over 'gap allowed' number of genes if continue along para seg, move on to new gene on focal seg\n",
    "                                    order1 += 1\n",
    "                                    order2 = order2 - noMatch2\n",
    "                                    noMatch2 = 0\n",
    "                                    noMatch1 += 1\n",
    "                                if noMatch1 >= gapAllowed + 1: #all genes within allowed gap from initial match have been checked on this side\n",
    "                                    blockBroken = True\n",
    "                                    if currentMatches >= minBlockSize: #check on block size before adding pairs from current block\n",
    "                                        possOhnos.extend(currentPairs)\n",
    "\n",
    "                        #right search\n",
    "                            order1 = 1\n",
    "                            order2 = 1\n",
    "                            noMatch1 = 0\n",
    "                            noMatch2 = 0\n",
    "                            blockBroken = False\n",
    "                            #vars for tracking the size of the current block to see if it meets minimum before it breaks\n",
    "                            currentPairs = [[gene,para]]\n",
    "                            currentMatches = 1 #not the same as number of pairs because one focal to two para (tandem dup) is only 1 syntenic match really\n",
    "\n",
    "                            while blockBroken == False:\n",
    "                                #catch index errors: checking if we've fallen off the right end\n",
    "                                try:\n",
    "                                    testGene1 = segGenes[seg][geneCount+order1]\n",
    "                                except IndexError: #focal seg right side exhausted, break\n",
    "    #                                 print('went off the right end of the focal seg:broke')\n",
    "                                    if currentMatches >= minBlockSize:\n",
    "                                        possOhnos.extend(currentPairs)\n",
    "\n",
    "                                    break\n",
    "                                try:\n",
    "                                    testGene2 = segGenes[seg2][pos+order2]\n",
    "                                except IndexError: #gone off the right end of the para seg, but if there are still focal genes to be tested can't just break out of the loop\n",
    "                                    #check if there's anything left to test\n",
    "                                    if noMatch1 == gapAllowed: #i.e. this is the 3rd focal gene tested with no matches found and we've now run out of para seg genes to test\n",
    "    #                                     print('Went off right end and no focal genes left:broke')\n",
    "                                        if currentMatches >= minBlockSize:\n",
    "                                            possOhnos.extend(currentPairs)\n",
    "\n",
    "                                        break\n",
    "                                    elif noMatch2 == 0: #last para seg gene was an ohnolog\n",
    "    #                                     print('last para seg gene was assigned as ohnolog, have to break')\n",
    "                                        if currentMatches >= minBlockSize:\n",
    "                                            possOhnos.extend(currentPairs)\n",
    "\n",
    "                                        break\n",
    "                                    else: #otherwise do normal change to next focal seg gene, go to next iteration\n",
    "    #                                     print('Went off right end with focal genes left: continue')\n",
    "                                        order1 += 1\n",
    "                                        order2 = order2 - noMatch2 #set para test position back to the last unmatched gene\n",
    "                                        noMatch2 = 0\n",
    "                                        noMatch1 += 1\n",
    "                                        continue\n",
    "                                #check for tandem, increment and continue if seems likely\n",
    "                                if (lastGene, testGene2) in paralogs or (testGene2, lastGene) in paralogs:\n",
    "                                    #is this a post or pre WGD tandem duplication?\n",
    "                                    if (testGene1, testGene2) in paralogs or (testGene2, testGene1) in paralogs: #also a paralog of the current test gene, possibly a pre-WGD dup\n",
    "                                        currentPairs.append([testGene1,testGene2])\n",
    "                                        currentMatches += 1\n",
    "                                        order1 += 1\n",
    "                                        order2 += 1\n",
    "                                        noMatch1 = 0\n",
    "                                        noMatch2 = 0\n",
    "                                        lastGene = testGene1\n",
    "                                    else:\n",
    "                                        currentPairs.append([lastGene,testGene2])\n",
    "                                        order2 +=1\n",
    "                                        continue\n",
    "                                else:\n",
    "                                    lastGene = '' #no tandem block detected, want to make sure we're not comparing this gene ten genes down the seg\n",
    "                                if (testGene1,testGene2) in paralogs or (testGene2,testGene1) in paralogs:\n",
    "                                    currentPairs.append([testGene1,testGene2])\n",
    "                                    currentMatches += 1\n",
    "                                    order1 += 1\n",
    "                                    order2 += 1\n",
    "                                    noMatch1 = 0\n",
    "                                    noMatch2 = 0\n",
    "                                    lastGene = testGene1\n",
    "                                else:\n",
    "                                    noMatch2 += 1\n",
    "                                    order2 += 1\n",
    "                                    lastGene = ''\n",
    "                                if noMatch2 >= gapAllowed + 1: #gap of over 2 genes if continue along para seg, move on to new gene on focal seg\n",
    "                                    order1 += 1\n",
    "                                    order2 = order2 - noMatch2\n",
    "                                    noMatch2 = 0\n",
    "                                    noMatch1 += 1\n",
    "                                if noMatch1 >= gapAllowed + 1: #all genes within a gap of 2 from initial match have been checked on this side\n",
    "                                    blockBroken = True\n",
    "                                    if currentMatches >= minBlockSize:\n",
    "                                        possOhnos.extend(currentPairs)\n",
    "\n",
    "\n",
    "                        else:\n",
    "            #                 print('same seg')\n",
    "                            pass\n",
    "                            \n",
    "            geneCount += 1\n",
    "        segCount += 1\n",
    "        print('Time elapsed:',round(time.time()-t,2)/60,'minutes!')\n",
    "    done = []\n",
    "    outFile = 'ohnologsWholeGenome_gapAllowed' + str(gapAllowed) + '_minBlock'+str(minBlockSize)+'.txt'\n",
    "    with open(outFile,'w') as file:\n",
    "        for x in possOhnos:\n",
    "            if x not in done:\n",
    "                done.append(x)\n",
    "                file.write('\\t'.join(x)+'\\n')\n",
    "    print('Finished this round! Pairs written to: ',outFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import and cleaning/processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in ohnolog sets\n",
    "cursor.execute('CREATE TABLE IF NOT EXISTS ohnologs_2010(id1,id2)')\n",
    "cursor.execute('CREATE TABLE IF NOT EXISTS ohnologs_singh1(id1,id2)')\n",
    "cursor.execute('CREATE TABLE IF NOT EXISTS ohnologs_singh2(id1,id2)')\n",
    "cursor.execute('CREATE TABLE IF NOT EXISTS ohnologs_singh3(id1,id2)')\n",
    "\n",
    "with open('ohnologs_2010.csv','r') as file:\n",
    "    file.readline()\n",
    "    file.readline()\n",
    "    for line in file:\n",
    "        line = line.strip('\\n').split(',')\n",
    "        ohno1, ohno2 = line[0],line[3]\n",
    "        cursor.execute('INSERT INTO ohnologs_2010 VALUES(?,?)',(ohno1,ohno2))\n",
    "\n",
    "with open('hsapiens.Pairs.Relaxed.2R.txt','r') as file1, \\\n",
    "    open('hsapiens.Pairs.Intermediate.2R.txt','r') as file2, \\\n",
    "    open('hsapiens.Pairs.Strict.2R.txt','r') as file3:\n",
    "    \n",
    "    for file,table in zip([file1,file2,file3],['ohnologs_singh1', 'ohnologs_singh2', 'ohnologs_singh3']):\n",
    "        file.readline()\n",
    "        for line in file:\n",
    "            line = line.strip('\\n').split('\\t')\n",
    "            ohno1, ohno2 = line[:2]\n",
    "            cursor.execute('INSERT INTO '+table+' VALUES(?,?)',(ohno1,ohno2))\n",
    "            \n",
    "cursor.execute('CREATE TABLE ohnologs_2020_8(id1 TEXT, id2 TEXT)')\n",
    "with open('ohnologsWholeGenome_gapAllowed8_minBlock3.txt') as file:\n",
    "    for line in file:\n",
    "        line = line.strip('\\n').split('\\t')\n",
    "        cursor.execute('INSERT INTO ohnologs_2020_8 VALUES(?,?)',(line[0],line[1]))\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entry of all genes to be considered, the straightforward downloadable-from-Ensembl features\n",
    "\n",
    "headers = {'Content-Type':'application/json'}\n",
    "cursor.execute('DROP TABLE IF EXISTS gene_features')\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS gene_features(id TEXT, trans_id TEXT, prot_id TEXT, name TEXT, \n",
    "                                                           chrom TEXT, start TEXT, end TEXT, strand TEXT, TSS INTEGER,\n",
    "                                                           genLen INTEGER, cdsLen INTEGER, transLen INTEGER,\n",
    "                                                           transCount INTEGER, intCount INTEGER, intCov REAL, intAvg REAL,\n",
    "                                                           gc REAL, gc3 REAL, domains INTEGER, u_domains INTEGER)''')\n",
    "geneMultiValDict = {}\n",
    "geneMultiValDict2 = {}\n",
    "with open('ensemblFeaturesv99.txt','r') as file: #initial dict has multiple lists of features for each gene due to multiple transcripts\n",
    "    print(file.readline().strip('\\n').split('\\t'))\n",
    "    for line in file:\n",
    "        line = line.strip('\\n').split('\\t') \n",
    "        gene = line[0]\n",
    "        if gene in geneMultiValDict.keys():\n",
    "            geneMultiValDict[gene].append(line[1:])\n",
    "        else:\n",
    "            geneMultiValDict[gene] = [line[1:]]\n",
    "\n",
    "with open('ensemblFeaturesv99_2.txt','r') as file:\n",
    "    print(file.readline().strip('\\n').split('\\t'))\n",
    "    for line in file:\n",
    "        line = line.strip('\\n').split('\\t') \n",
    "        gene = line[0]\n",
    "        if gene in geneMultiValDict2.keys():\n",
    "            geneMultiValDict2[gene].append(line[1:])\n",
    "        else:\n",
    "            geneMultiValDict2[gene] = [line[1:]]\n",
    "\n",
    "for gene in tqdm(geneMultiValDict):\n",
    "#         trans, prot, chr, start, end, tss, tlen, strand, name, clen, tcount, erank, estart, eend\n",
    "#         gc content, pfam domain id, protein id\n",
    "    #get genomic length\n",
    "    chrom = geneMultiValDict[gene][0][2]\n",
    "    tss = geneMultiValDict[gene][0][5]\n",
    "    strand = geneMultiValDict[gene][0][7]\n",
    "    name = geneMultiValDict[gene][0][8]\n",
    "    transCount = geneMultiValDict[gene][0][10]\n",
    "    start = min([int(geneMultiValDict[gene][0][4]),int(geneMultiValDict[gene][0][3])])\n",
    "    end = max([int(geneMultiValDict[gene][0][4]),int(geneMultiValDict[gene][0][3])])\n",
    "    genLen = abs(end-start) \n",
    "    #get longest transcript\n",
    "    transPlusLen = [(x[0],int(x[6])) for x in geneMultiValDict[gene]]\n",
    "    longestTrans = max(transPlusLen, key=lambda x: x[1])[0]\n",
    "    longestTransLen = max(transPlusLen, key=lambda x: x[1])[1]\n",
    "    #get protein for longest CDS\n",
    "    protPlusLen = [(x[1],int(x[9])) for x in geneMultiValDict[gene] if x[1] != '']\n",
    "    longestProt = max(protPlusLen, key=lambda x: x[1])[0]\n",
    "    longestProtLen = max(protPlusLen, key=lambda x: x[1])[1]\n",
    "    #get max exon rank for number of exons (number of introns = this -1)\n",
    "    intCount = max([int(x[11]) for x in geneMultiValDict[gene] if x[0] == longestTrans]) -1\n",
    "    #intron avg len and coverage for longest transcript\n",
    "    #get all exon coords for longest transcript\n",
    "    exonList= [(int(x[12]),int(x[13])) for x in geneMultiValDict[gene] if x[0] == longestTrans]\n",
    "    count = 0\n",
    "    intLens = []\n",
    "    exonList = sorted(exonList, key=lambda x: x[0])\n",
    "    for start2, end2 in exonList:\n",
    "        if count == 0: #first exon\n",
    "            nextStart = end2\n",
    "            count += 1\n",
    "            continue\n",
    "#             elif count == len(exonList) -1: #last exon\n",
    "#                 intEnd = \n",
    "        else:\n",
    "            intStart = nextStart\n",
    "            intEnd = start2\n",
    "            nextStart = end2\n",
    "        \n",
    "        intLens.append(abs(intEnd-intStart))\n",
    "        count += 1\n",
    "    intCount = len(intLens)\n",
    "    intCov = sum(intLens)/genLen\n",
    "    intAvg = np.mean(intLens)\n",
    "    \n",
    "    gc = geneMultiValDict2[gene][0][0]\n",
    "    domainList = [x[1] for x in geneMultiValDict2[gene] if x[2] == longestProt]\n",
    "    domainCount = len(domainList)\n",
    "    uniqDomainCount = len(set(domainList))\n",
    "            \n",
    "# also any that need the API -gc3\n",
    "    try:\n",
    "        res = requests.get('https://rest.ensembl.org/sequence/id/'+longestTrans+'?type=cds',headers=headers).json()\n",
    "    except Exception as e: #connection errors, try waiting a little and going again, but give up after that\n",
    "        print(e)\n",
    "        time.sleep(5)\n",
    "        try:\n",
    "            res = requests.get('https://rest.ensembl.org/sequence/id/'+longestTrans+'?type=cds',headers=headers).json()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(gene,': failed to fetch sequence')\n",
    "            continue\n",
    "    try:\n",
    "        seq = res['seq']\n",
    "    except KeyError: #transcript not found, check to see if more than one exists for this gene\n",
    "        if len(transPlusLen) == 1:\n",
    "            continue #only one transcript and it's not found\n",
    "        else:\n",
    "            tried = [longestTrans]\n",
    "            while len(tried) < len(transPlusLen):\n",
    "                longestTrans = max([x for x in transPlusLen if x not in tried], key=lambda x: x[1])[0]\n",
    "                longestTransLen = max([x for x in transPlusLen if x not in tried], key=lambda x: x[1])[1]\n",
    "            \n",
    "                res = requests.get('https://rest.ensembl.org/sequence/id/'+longestTrans+'?type=cds',headers=headers).json()\n",
    "                try:\n",
    "                    seq = res['seq']\n",
    "                    break\n",
    "                except KeyError:\n",
    "                    tried.append(longestTrans)\n",
    "                    continue\n",
    "            else:\n",
    "                continue\n",
    "    pos3 = seq[2::3]\n",
    "    gc3 = (len([x for x in pos3 if x == 'G' or x == 'C'])/len(pos3))*100\n",
    "    insert = 'INSERT INTO gene_features VALUES(' + ','.join(['?' for x in range(20)]) + ')'\n",
    "    cursor.execute(insert,(gene,longestTrans,longestProt,name,chrom,start,end,strand,tss,genLen,longestProtLen,int(longestTransLen),\n",
    "                        transCount,intCount,intCov,float(intAvg),float(gc),gc3,domainCount,uniqDomainCount))\n",
    "\n",
    "    db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('''ALTER TABLE gene_features ADD COLUMN motif_number_1k INTEGER''')\n",
    "cursor.execute('''SELECT id FROM gene_features WHERE motif_number_1K IS NULL''')\n",
    "ids = [x[0] for x in cursor.fetchall()]\n",
    "\n",
    "counter = 0\n",
    "t = time.time()\n",
    "\n",
    "for i in ids:\n",
    "    counter += 1\n",
    "    cursor.execute('''SELECT chrom, start, end FROM gene_features WHERE id ==?''', (i,))\n",
    "    l = cursor.fetchall()[0]\n",
    "    loc = str(l[0]) + ':' + str(int(l[1])-1000) + '-' + str(int(l[2])+1000)\n",
    "    print('Going to make request')\n",
    "    url = \"http://rest.ensembl.org/overlap/region/human/\" + loc + \"?feature=motif\"\n",
    "    headers = { \"Content-Type\" : \"application/json\"}\n",
    "    r = requests.get(url, headers=headers).json()\n",
    "    print(r)\n",
    "    break\n",
    "\n",
    "    if r != []:\n",
    "        cursor.execute('''UPDATE gene_features SET motif_number_1k =? WHERE id == ?''', (len(r), i))\n",
    "    else:\n",
    "        cursor.execute('''UPDATE gene_features SET motif_number_1k = 0 WHERE id == ?''', (i,))\n",
    "#     time.sleep(0.07)\n",
    "    if counter% 200 == 0:\n",
    "        print(counter, time.time()-t, 'seconds since started')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evolution rate\n",
    "cursor.execute('CREATE TABLE IF NOT EXISTS macaqueOrthologs(id TEXT, m_id TEXT, orthoType TEXT, dN REAL, dS REAL)')\n",
    "with open('macaqueOrthoV99.txt','r') as file:\n",
    "    file.readline()\n",
    "    for line in file:\n",
    "        line = line.strip('\\n').split('\\t')\n",
    "        i, mi, t, dn,ds = line\n",
    "        cursor.execute('INSERT INTO macaqueOrthologs VALUES(?,?,?,?,?)',(i,mi,t,dn,ds))\n",
    "db.commit()\n",
    "\n",
    "cursor.execute('ALTER TABLE gene_features ADD COLUMN evolRate REAL')\n",
    "cursor.execute('''UPDATE gene_features \n",
    "                SET evolRate = \n",
    "               (SELECT AVG(dN/dS) FROM\n",
    "                   macaqueOrthologs\n",
    "                   WHERE gene_features.id == macaqueOrthologs.id AND dS >= 0.01)''')\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other features from papers\n",
    "# expression - GTEX medians and other expression sources (HBDR and FANTOM)\n",
    "cursor.execute(\"SELECT id FROM gene_features\")\n",
    "ids = [x[0] for x in cursor.fetchall()]\n",
    "print('Reading in expression datasets')\n",
    "with open('GTEx_Analysis_2017-06-05_v8_RNASeQCv1.1.9_gene_median_tpm.gct', 'r') as med_file, \\\n",
    "    open('devExp.tpms.tsv','r') as dev_file, open('devExpFantom.tpms.tsv', 'r') as f_dev_file, \\\n",
    "    open('brainDev.tpms.tsv', 'r') as brain_file:\n",
    "    exp_dict = {}\n",
    "    for i in range(2):\n",
    "        med_file.readline()\n",
    "    \n",
    "    header = med_file.readline().strip().split('\\t')\n",
    "    for line in med_file:\n",
    "        line = line.strip().split('\\t')\n",
    "        gene = re.search(r'(.*)\\.(.*)', line[0]).group(1) #remove version number on gene ID\n",
    "        if gene in ids:\n",
    "            exp_dict[gene] = [x for x in zip(header[2:],[float(x) for x in line[2:]])]\n",
    "    for i in range(1,5):\n",
    "        f_dev_file.readline()\n",
    "    header = f_dev_file.readline().strip().split('\\t')\n",
    "    f_list = []\n",
    "    for name in header:\n",
    "        if 'fetal' in name:\n",
    "            f_list.append(header.index(name))\n",
    "    for line in f_dev_file:\n",
    "        line = line.strip('\\n').split('\\t')\n",
    "        if line[0] in ids:\n",
    "            start = line[0:2]\n",
    "            start.extend([0 if x == '' else float(x) for x in line[2:]])\n",
    "            line = start\n",
    "            for i in f_list:\n",
    "                try:\n",
    "                    exp_dict[line[0]].append((header[i],line[i]))\n",
    "                except (KeyError, IndexError):\n",
    "                    exp_dict[line[0]] = [(header[i],line[i])]\n",
    "    \n",
    "    for i in range(1,5):\n",
    "        brain_file.readline()\n",
    "    header = brain_file.readline().strip('\\n').split('\\t')\n",
    "    for line in brain_file:\n",
    "        line = line.strip('\\n').split('\\t')\n",
    "        if line[0] in ids:\n",
    "            start = line[0:2]\n",
    "            start.extend([0 if x == '' else float(x) for x in line[2:]])\n",
    "            line = start\n",
    "            for i in range(2, len(line)):\n",
    "                try:\n",
    "                    exp_dict[line[0]].append((header[i],line[i]))\n",
    "                except KeyError:\n",
    "                    exp_dict[line[0]] = [(header[i],line[i])]\n",
    "    for i in range(4):\n",
    "        dev_file.readline()\n",
    "    header = dev_file.readline().strip().split('\\t')\n",
    "    d_list = []\n",
    "    for name in header:\n",
    "        if 'conception' in name:\n",
    "            d_list.append(header.index(name))\n",
    "    print(d_list)\n",
    "    for line in dev_file:\n",
    "        line = line.strip('\\n').split('\\t')\n",
    "        if line[0] in ids:\n",
    "            start = line[0:2]\n",
    "            start.extend([0 if x == '' else float(x) for x in line[2:]])\n",
    "            line = start\n",
    "            for i in d_list:\n",
    "                try:\n",
    "                    exp_dict[line[0]].append((header[i],line[i]))\n",
    "                except (KeyError, IndexError):\n",
    "                    exp_dict[line[0]] = [(header[i],line[i])]\n",
    "    \n",
    "for k in [x for x in exp_dict.keys()][:5]:\n",
    "        print(k,exp_dict[k])\n",
    "count = 0\n",
    "print('Updating table now! Expression values')\n",
    "cursor.execute('ALTER TABLE gene_features ADD COLUMN max_exp REAL')\n",
    "cursor.execute('ALTER TABLE gene_features ADD COLUMN max_tissue TEXT')\n",
    "cursor.execute('''SELECT id FROM gene_features''')\n",
    "ids = [x[0] for x in cursor.fetchall()]\n",
    "timer = time.time()\n",
    "for i in ids:\n",
    "    try:\n",
    "        expression_list = exp_dict[i]\n",
    "#         expression_list = [float(x[]) for x in expression_list]\n",
    "        mT, mE = max(expression_list,key=lambda x: x[1])\n",
    "        cursor.execute('''UPDATE gene_features SET max_exp = ?, max_tissue = ? WHERE id == ?''', (mE,mT,i))\n",
    "        count += 1\n",
    "        if count % 500 == 0:\n",
    "            print(count, time.time()-timer)\n",
    "    except KeyError:\n",
    "        count += 1\n",
    "        if count % 500 == 0:\n",
    "            print(count, time.time()-timer)\n",
    "        continue\n",
    "db.commit()\n",
    "# Specificity\n",
    "def tau(expression_list):\n",
    "    expression_list = [float(x[1]) for x in expression_list]\n",
    "    m = max(expression_list)\n",
    "    try:\n",
    "        expression_list = [x/m for x in expression_list]\n",
    "    except ZeroDivisionError:\n",
    "        return(None)\n",
    "    num_list = []\n",
    "    for i in expression_list:\n",
    "        num_list.append(1-i)\n",
    "    s = sum(num_list)\n",
    "    try:\n",
    "        res = s/ (len(expression_list)-1)\n",
    "    except ZeroDivisionError:\n",
    "        print(expression_list)\n",
    "        return(None)\n",
    "    return(res)\n",
    "cursor.execute('''ALTER TABLE gene_features ADD COLUMN specificity REAL''')\n",
    "count = 0\n",
    "timer = time.time()\n",
    "for k in exp_dict:\n",
    "    expressed = 0\n",
    "    for x in exp_dict[k]:\n",
    "        x = x[1]\n",
    "        if float(x) >= 1:\n",
    "            expressed = 1\n",
    "    if expressed == 1:\n",
    "        t = tau(exp_dict[k])\n",
    "        cursor.execute('''UPDATE gene_features SET specificity = ? WHERE id == ?''', (t, k))\n",
    "    count += 1\n",
    "    if count % 500 == 0:\n",
    "        print(count,time.time()-timer)\n",
    "db.commit()\n",
    "print('Essentiality')\n",
    "# CRISPR score - Wang et al\n",
    "#essentiality\n",
    "cursor.execute('ALTER TABLE gene_features ADD COLUMN ess REAL')\n",
    "with open('Wang_CRISPR.csv', 'r') as file:\n",
    "    file.readline()\n",
    "    for line in file:\n",
    "        l = line.strip().split(',')\n",
    "        geneName, KBM7, K562, Jiyoye, Raji = l[0], float(l[2]), float(l[4]), float(l[6]), float(l[8])\n",
    "        scoreList = [KBM7, K562, Jiyoye, Raji]\n",
    "        ess = min(scoreList)\n",
    "        cursor.execute('''UPDATE gene_features SET ess = ? WHERE name == ?''', \n",
    "                       (ess, geneName))\n",
    "        db.commit()\n",
    "# PPIs: human interactome data HuRI_2_10_2019.tsv\n",
    "print('PPIs')\n",
    "cursor.execute('CREATE TABLE IF NOT EXISTS interactions(id1 TEXT,id2 TEXT)')\n",
    "cursor.execute('ALTER TABLE gene_features ADD COLUMN PPIs REAL')\n",
    "with open('HuRI_2_10_2019.tsv','r') as file:\n",
    "    file.readline()\n",
    "    for line in file:\n",
    "        line = line.strip('\\n').split('\\t')\n",
    "        id1, id2 = line[:2]\n",
    "        cursor.execute('INSERT INTO interactions VALUES(?,?)',(id1,id2))\n",
    "db.commit()\n",
    "cursor.execute('UPDATE gene_features SET PPIs = (SELECT COUNT(*) FROM interactions WHERE (id1 == id) OR (id2 == id))')\n",
    "db.commit()\n",
    "print('Pop based essentiality')\n",
    "# # EvoTol\n",
    "cursor.execute('ALTER TABLE gene_features ADD COLUMN EvoTol REAL')\n",
    "cursor.execute('SELECT name from gene_features')\n",
    "names = [x[0] for x in cursor.fetchall()]\n",
    "for i in names:\n",
    "    url = 'http://www.evotol.co.uk/genes_json?genes=' + i + '&ont=all&thresh=1'\n",
    "    try:\n",
    "        res = requests.get(url).json()\n",
    "        if res['table'] == []:\n",
    "            score = None\n",
    "        else:\n",
    "            score = res['table'][0][1]\n",
    "    except ConnectionError:\n",
    "        score = None\n",
    "    time.sleep(0.6)\n",
    "    cursor.execute('UPDATE gene_features SET EvoTol = ? WHERE name == ?',(score,i))\n",
    "db.commit()\n",
    "# LoFTool\n",
    "cursor.execute('ALTER TABLE gene_features ADD COLUMN loftool_percentile REAL')\n",
    "with open('loftool_scores_table.csv','r') as file:\n",
    "    file.readline()\n",
    "    for line in tqdm(file):\n",
    "        line = line.strip('\\n').split(',')\n",
    "        name, score = line[0],float(line[3])\n",
    "        cursor.execute('UPDATE gene_features SET loftool_percentile = ? WHERE name == ?',(score,name))\n",
    "db.commit()\n",
    "# Phi\n",
    "cursor.execute('ALTER TABLE gene_features ADD COLUMN Phi REAL')\n",
    "with open('phi_scores.txt','r') as file:\n",
    "    for i in range(0,8):\n",
    "        file.readline()\n",
    "    for line in file:\n",
    "        line = line.strip('\\n').split(' ')\n",
    "        name,score = line[0],line[1]\n",
    "        cursor.execute('UPDATE gene_features SET Phi = ? WHERE name == ?',(score,name))\n",
    "db.commit()\n",
    "# pLI and missense Z score in one file from gnomad\n",
    "cursor.execute('ALTER TABLE gene_features ADD COLUMN syn_Z_score REAL')\n",
    "cursor.execute('ALTER TABLE gene_features ADD COLUMN mis_Z_score REAL')\n",
    "cursor.execute('ALTER TABLE gene_features ADD COLUMN lof_Z_score REAL')\n",
    "cursor.execute('ALTER TABLE gene_features ADD COLUMN pLI_score REAL')\n",
    "headers = {'Content-Type':'application/json'}\n",
    "with open('gnomad.v2.1.1.lof_metrics.by_gene.txt','r') as file:\n",
    "#gene id in col 64 (ind 63) for some godforsaken reason\n",
    "# ind 31,32,33 = z scores for syn, missense and LOF\n",
    "# ind 20 is pLI, prob intolerant of het and homo LOF\n",
    "    file.readline()\n",
    "    for line in file:\n",
    "        line = line.strip('\\n').split('\\t')\n",
    "        gene = line[63]\n",
    "        z_syn, z_miss, z_lof, pli = line[31],line[32],line[33],line[20]\n",
    "\n",
    "        cursor.execute('UPDATE gene_features SET syn_Z_score = ?, mis_Z_score = ?,lof_Z_score = ?, pLI_score = ? WHERE id == ?',(z_syn,z_miss,z_lof,pli,gene))\n",
    "db.commit()\n",
    "# Shet\n",
    "cursor.execute('ALTER TABLE gene_features ADD COLUMN s_het REAL')\n",
    "with open('shet_estimates.csv','r') as file:\n",
    "    file.readline()\n",
    "    for line in file:\n",
    "        line = line.strip('\\n').split(',')\n",
    "        name, shet = line[:2]\n",
    "        cursor.execute('UPDATE gene_features SET s_het = ? WHERE name == ?',(shet,name))\n",
    "db.commit()\n",
    "# RVIS\n",
    "cursor.execute('ALTER TABLE gene_features ADD COLUMN RVIS REAL')\n",
    "with open('GenicIntolerance_v3_12Mar16.txt','r') as file:\n",
    "    file.readline()\n",
    "    for line in tqdm(file):\n",
    "        line = line.strip('\\n').split('\\t')\n",
    "        name,score,excl = line[0],line[2],line[16]\n",
    "        if excl == 'Y':\n",
    "            continue\n",
    "        else:\n",
    "            cursor.execute('UPDATE gene_features SET RVIS = ? WHERE name == ?',(score,name))\n",
    "db.commit()\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features requiring external calculations\n",
    "# CAI\n",
    "cursor.execute('ALTER TABLE gene_features ADD COLUMN CAI REAL')\n",
    "cursor.execute('SELECT id,trans_id FROM gene_features')\n",
    "cList = cursor.fetchall()\n",
    "h= {\"Content-Type\" : \"text/plain\"}\n",
    "print('Fetching sequences')\n",
    "done = []\n",
    "with open('cdsSequence.fa','r') as file:\n",
    "    for line in file:\n",
    "        if line.startswith('>'):\n",
    "            i = line.strip('>').strip('\\n')\n",
    "            done.append(i)\n",
    "counter = 0\n",
    "error = []\n",
    "with open('cdsSequence.fa','w') as file:\n",
    "    for ID,transID in cList:\n",
    "        if ID in done:\n",
    "            continue\n",
    "        url = \"https://rest.ensembl.org/sequence/id/\" + transID + \"?type=cds;multiple_sequences=1\"\n",
    "        try:\n",
    "            r = requests.get(url, headers=h).text\n",
    "        except Exception as e:\n",
    "            print(\"Error {}\".format(e))\n",
    "            error.append(ID)\n",
    "\n",
    "        #get longest CDS, multiple sequences are returned separated by newline\n",
    "        cds = max(r.split('\\n'), key=len)\n",
    "        file.write('>'+ID+'\\n')\n",
    "        file.write(cds+'\\n')\n",
    "        counter += 1\n",
    "        time.sleep(0.07)\n",
    "        if counter%100 == 0:\n",
    "            print(counter,'done')\n",
    "print('IDs not completed:')\n",
    "print(error)\n",
    "print('Calculating CAI')\n",
    "cmd = 'perl CAIcal_ECAI_v1.4_source/CAIcal_ECAI_v1.4.pl -f cdsSequence.fa -h CAIcal_ECAI_v1.4_source/human -o1 totalCAI.txt -o2 totalRandSeq.txt -o3 totalExpectCAI.txt'.split(' ')\n",
    "p = Popen(cmd ,stdin=PIPE, stdout=PIPE, stderr=PIPE)\n",
    "out, err = p.communicate()\n",
    "print('Updating table')\n",
    "cursor.execute('SELECT id FROM gene_features WHERE CAI IS NULL')\n",
    "doneIDs = [x[0] for x in cursor.fetchall()]\n",
    "with open('totalCAI.txt','r') as file:\n",
    "    file.readline()\n",
    "    for line in tqdm(file):\n",
    "        line = line.strip('\\n').strip('>').split('\\t')\n",
    "        if line[0] in doneIDs:\n",
    "            continue\n",
    "        if 'Error' in line[1]:\n",
    "            line[1] = 'Error-check'\n",
    "        cursor.execute('UPDATE gene_features SET CAI = ? WHERE id == ?',(line[1],line[0]))\n",
    "db.commit()\n",
    "print()\n",
    "#IDRs\n",
    "cursor.execute('ALTER TABLE gene_features ADD COLUMN IntDisProp REAL')\n",
    "cursor.execute('SELECT id,trans_id FROM gene_features WHERE IntDisProp IS NULL')\n",
    "idList = [x for x in cursor.fetchall()]\n",
    "print('Calculating intrinsic disorder')\n",
    "for i,ID in idList:\n",
    "    disCount = 0\n",
    "    url = \"https://rest.ensembl.org/sequence/id/\" + ID + \"?type=protein;multiple_sequences=1\"\n",
    "    r = requests.get(url, headers=h).text\n",
    "    #get longest CDS, multiple sequences are returned separated by newline\n",
    "    prot = max(r.split('\\n'), key=len)\n",
    "    protLen = len(prot)\n",
    "    Input = '>' + i + '\\n' + prot +'\\n'\n",
    "    with open('tempProt.fa','w') as file:\n",
    "        file.write(Input)\n",
    "    cmd = 'python IUPRED/iupred2a.py tempProt.fa long'.split(' ')\n",
    "    p = Popen(cmd,stdin=PIPE, stdout=PIPE, stderr=PIPE)\n",
    "    out, err = p.communicate()\n",
    "    for line in out.decode().split('\\n'):\n",
    "        if line.startswith('#'):\n",
    "            continue\n",
    "        else:\n",
    "            line = line.split('\\t')\n",
    "            if line != ['']:\n",
    "                intDis = line[2]\n",
    "            else:\n",
    "                continue\n",
    "            if float(intDis) >= 0.5:\n",
    "                disCount += 1\n",
    "    cursor.execute('UPDATE gene_features SET IntDisProp = ? WHERE id == ?',(disCount/protLen,i))\n",
    "cursor.execute('UPDATE paralogy SET preVertebrata = \"F\" WHERE preVertebrata IS NULL')\n",
    "db.commit()\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplication category assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating of paralog table\n",
    "cursor.execute('CREATE TABLE IF NOT EXISTS paralogy(id TEXT, para TEXT, age TEXT,dN REAL,dS REAL,singleton TEXT, retro TEXT, preVertebrata TEXT, ohno_2010 TEXT, ohno_singh_1 TEXT, ohno_singh2 TEXT, ohno_sing3 TEXT, ohno_2020 TEXT)')\n",
    "old_tax_list = ['Opisthokonta','Animalia','Bilateria', 'Chordata'] \n",
    "new_tax_list = ['Vertebrata','Gnathostomata','Euteleostomi', 'Sarcopterygii', 'Tetrapoda', \n",
    "                'Amniota', 'Mammalia', 'Theria', 'Eutheria','Boreoeutheria',  \n",
    "                'Euarchontoglires', 'Primates', 'Haplorrhini', 'Simiiformes',\n",
    "                'Catarrhini', 'Hominoidea', 'Hominidae','Homininae', 'Homo sapiens']\n",
    "insList, insListPreV, insListSing = [],[],[]\n",
    "with open('ensemblParalogsv99_2.txt','r') as file:\n",
    "    file.readline()\n",
    "    for line in tqdm(file):\n",
    "        line = line.strip('\\n').split('\\t')\n",
    "        i, p, age,dn,ds = line\n",
    "        if age in old_tax_list:\n",
    "            insListPreV.append((i,p,age,dn,ds,'T')) # pre-vertebrate duplication\n",
    "        elif p == '': #singleton - no paralog\n",
    "            insListSing.append((i,'T'))\n",
    "        else:\n",
    "            insList.append((i,p,age,dn,ds))\n",
    "print('Running inserts...')\n",
    "cursor.executemany('INSERT INTO paralogy(id,para,age,dN,dS,preVertebrata) VALUES(?,?,?,?,?,?)',insListPreV)\n",
    "cursor.executemany('INSERT INTO paralogy(id,singleton) VALUES (?,?)',insListSing)\n",
    "cursor.executemany('INSERT INTO paralogy(id,para,age,dN,dS) VALUES(?,?,?,?,?)',insList)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign ohnolog status to each paralog pair in paralogy table\n",
    "cursor.execute('''UPDATE paralogy \n",
    "                   SET ohno_2020 == \"T\" \n",
    "                       WHERE EXISTS \n",
    "                           (SELECT * FROM ohnologs_2020 AS o \n",
    "                               WHERE (o.id == paralogy.id AND o.id2 == paralogy.para) OR (o.id == paralogy.para AND o.id2 == paralogy.id))''')\n",
    "cursor.execute('''UPDATE paralogy \n",
    "                   SET ohno_2010 == \"T\" \n",
    "                       WHERE EXISTS \n",
    "                           (SELECT * FROM ohnologs_2010 AS o \n",
    "                           WHERE (o.id1 == paralogy.id AND o.id2 == paralogy.para) OR (o.id1 == paralogy.para AND o.id2 == paralogy.id))''')\n",
    "cursor.execute('''UPDATE paralogy \n",
    "                   SET ohno_singh_1 == \"T\" \n",
    "                       WHERE EXISTS \n",
    "                           (SELECT * FROM ohnologs_singh1 AS o \n",
    "                               WHERE (o.id1 == paralogy.id AND o.id2 == paralogy.para) OR (o.id1 == paralogy.para AND o.id2 == paralogy.id))''')\n",
    "cursor.execute('''UPDATE paralogy \n",
    "                   SET ohno_singh2 == \"T\" \n",
    "                       WHERE EXISTS \n",
    "                           (SELECT * FROM ohnologs_singh2 AS o \n",
    "                               WHERE (o.id1 == paralogy.id AND o.id2 == paralogy.para) OR (o.id1 == paralogy.para AND o.id2 == paralogy.id))''')\n",
    "cursor.execute('''UPDATE paralogy \n",
    "                   SET ohno_sing3 == \"T\" \n",
    "                       WHERE EXISTS \n",
    "                           (SELECT * FROM ohnologs_singh3 AS o \n",
    "                               WHERE (o.id1 == paralogy.id AND o.id2 == paralogy.para) OR (o.id1 == paralogy.para AND o.id2 == paralogy.id))''')\n",
    "#add in F for not ohnologous pairs because I don't want to re-write the queries that use that\n",
    "cursor.execute('''UPDATE paralogy \n",
    "                   SET ohno_2020 == \"F\" \n",
    "                    WHERE ohno_2020 IS NULL''')\n",
    "cursor.execute('''UPDATE paralogy \n",
    "                   SET ohno_2010 == \"F\" \n",
    "                    WHERE ohno_2010 IS NULL''')\n",
    "cursor.execute('''UPDATE paralogy \n",
    "                   SET ohno_singh_1 == \"F\" \n",
    "                    WHERE ohno_singh_1 IS NULL''')\n",
    "cursor.execute('''UPDATE paralogy \n",
    "                   SET ohno_singh2 == \"F\" \n",
    "                    WHERE ohno_singh2 IS NULL''')\n",
    "cursor.execute('''UPDATE paralogy \n",
    "                   SET ohno_sing3 == \"F\" \n",
    "                    WHERE ohno_sing3 IS NULL''')\n",
    "\n",
    "# assign retroduplication status for all pairs\n",
    "cursor.execute('''SELECT id, para FROM paralogy WHERE (singleton != \"T\" OR singleton IS NULL) AND retro IS NULL''')\n",
    "paraRes = cursor.fetchall()\n",
    "print(len(paraRes))\n",
    "\n",
    "cursor.execute('SELECT id, chrom FROM gene_features')\n",
    "chromDict = dict(cursor.fetchall())\n",
    "for key in chromDict:\n",
    "    chromDict[key] = str(chromDict[key])\n",
    "\n",
    "startTime = time.time()\n",
    "doneCount = 0\n",
    "\n",
    "# work by pair\n",
    "syntenyCases = 0\n",
    "for i, p in paraRes:\n",
    "   \n",
    "    localSynteny = False\n",
    "    doneCount += 1\n",
    "    cursor.execute('SELECT intCount,id FROM gene_features WHERE id == ? OR id == ?',(i,p))\n",
    "    res = cursor.fetchall()\n",
    "    try:\n",
    "        count1 = [x[0] for x in res if x[1] == i][0]\n",
    "        count2 = [x[0] for x in res if x[1] == p][0]\n",
    "    except IndexError:\n",
    "        continue #missing id, likley non-coding paralog\n",
    "\n",
    "#     check if meets the retro test off the bat: one has 0 introns and the other has at least 3\n",
    "    if (count1 == 0 or count2 == 0) and (count1 >= 3 or count2 >= 3): \n",
    "        cursor.execute('UPDATE paralogy SET retro == \"T\" WHERE id == ? AND para == ?' ,(i,p))\n",
    "        continue\n",
    "        \n",
    "#     if doesn't meet the retro requirement but needs more investigation due to low intron counts: synteny\n",
    "    elif (count1 == 0 and count2 == 0) or ((count1 == 0 or count2 == 0) and (count1 < 3 or count2 < 3)):  \n",
    "        # double zero pairs, or one zero and they other less than 3\n",
    "        syntenyCases += 1\n",
    "        try:\n",
    "            c1 = chromDict[i]\n",
    "            c2 = chromDict[p]\n",
    "        except KeyError:\n",
    "            #missingPairs.append((i,p)) #this is prob an issue if I'm going to use non-coding pairs, I guess they go in the 'full_paralogs' table?\n",
    "            continue\n",
    "\n",
    "#         cursor.execute('SELECT DISTINCT id, gene_start, gene_end, chr FROM full_paralogs WHERE chr == ? OR chr == ?', (c1,c2))\n",
    "        cursor.execute('SELECT id, start, end, chrom FROM gene_features WHERE chrom == ? or chrom == ?',(c1,c2))\n",
    "        res = cursor.fetchall()\n",
    "        locList1 = [x[:3] for x in res if x[3] == c1]\n",
    "        locList2 = [x[:3] for x in res if x[3] == c2]\n",
    "\n",
    "        locList1 = [x if (x[2] > x[1]) else (x[0],x[2],x[1]) for x in locList1]\n",
    "        locList2 = [x if (x[2] > x[1]) else (x[0],x[2],x[1]) for x in locList2] #getting lists of genes on chromosome, making sure start is lower number\n",
    "\n",
    "        orderList1 = [x[0] for x in sorted(locList1, key= lambda x: x[1])]\n",
    "        orderList2 = [x[0] for x in sorted(locList2, key= lambda x: x[1])] #ordered lists of genes on the relevant chromosomes\n",
    "\n",
    "        try:\n",
    "            ind1 = orderList1.index(i)\n",
    "        except:\n",
    "            print(i, type(c1), doneCount)\n",
    "        #checks for the location of the gene on the chromosome\n",
    "        if ind1 < 5:\n",
    "            geneListLeft1 = orderList1[0:ind1]\n",
    "        elif ind1 > len(orderList1)-6: # -6 because of 0 indexing\n",
    "            geneListRight1 = orderList1[ind1+1:]\n",
    "\n",
    "        else:\n",
    "            startInd1 = ind1 - 5\n",
    "            endInd1 = ind1 + 6 #because of 'up to but not including'\n",
    "        \n",
    "            geneListLeft1 = orderList1[startInd1:ind1]\n",
    "            geneListRight1 = orderList1[ind1+1:endInd1]\n",
    "        #same checks but for the paralog\n",
    "        ind2 = orderList2.index(p)\n",
    "        if ind2 < 5:\n",
    "            geneListLeft2 = orderList2[0:ind2]\n",
    "            \n",
    "        elif ind2 > len(orderList2)-6: # -6 because of 0 indexing\n",
    "            geneListRight2 = orderList2[ind2+1:]\n",
    "            \n",
    "        else:\n",
    "            startInd2 = ind2 - 5\n",
    "            endInd2 = ind2 + 6 #because of 'up to but not including'\n",
    "\n",
    "            geneListLeft2 = orderList2[startInd2:ind2]\n",
    "            geneListRight2 = orderList2[(ind2+1):endInd2]\n",
    "\n",
    "        geneListLeft1.extend(geneListRight1) #not bothered properly changing to mashed together list\n",
    "        geneListLeft2.extend(geneListRight2) #lists of all the genes to be considered on either side of the pair in question\n",
    "\n",
    "        matchList = []\n",
    "\n",
    "        for a,b in itertools.product(geneListLeft1,geneListLeft2):\n",
    "            if (a,b) in set(paraRes) or (b,a) in set(paraRes):\n",
    "                #genes are paralogous\n",
    "                if not((a,b) in matchList or (b,a) in matchList):\n",
    "                    matchList.append((a,b))\n",
    "    \n",
    "    # iterate over pairs in gene lists testing if they have matches\n",
    "        for j in range(0,len(geneListLeft1)-1):\n",
    "            gene1, gene2 = geneListLeft1[j], geneListLeft1[j+1]\n",
    "            # do both have a match\n",
    "            if gene1 in flatten(matchList) and gene2 in flatten(matchList):\n",
    "        #         get all the matches for these two genes and see are any collinear in geneListLeft2 specifically\n",
    "        #         this is messier than it should be because of genes in tandem - some ids will appear in both lists\n",
    "                gene1Matches = [x[0] for x in matchList if (x[1] == gene1 and x[0] in geneListLeft2)]\n",
    "                gene1Matches.extend([x[1] for x in matchList if (x[0] == gene1 and x[1] in geneListLeft2)])\n",
    "\n",
    "                gene2Matches = [x[0] for x in matchList if (x[1] == gene2 and x[0] in geneListLeft2)]\n",
    "                gene2Matches.extend([x[1] for x in matchList if (x[0] == gene2 and x[1] in geneListLeft2)])\n",
    "\n",
    "                # are their matches colinear (in the other gene order so geneListLeft2)\n",
    "                for gene1Match, gene2Match in itertools.product(gene1Matches,gene2Matches):\n",
    "                    match1Order, match2Order = geneListLeft2.index(gene1Match), geneListLeft2.index(gene2Match)\n",
    "                    if abs(match1Order - match2Order) == 1:\n",
    "                        cursor.execute('UPDATE paralogy SET retro = \"F\" WHERE id == ? AND para == ?', (i,p))\n",
    "                        break\n",
    "                else:\n",
    "                    continue #continue to next j only if no match found, if the for breaks we break out of the outer loop too\n",
    "                break\n",
    "        else:\n",
    "#           doesn't meet retro requirement and lacks synteny, inconclusive\n",
    "            cursor.execute('UPDATE paralogy SET retro = \"I\" WHERE id == ? AND para == ?', (i,p))\n",
    "    else:\n",
    "#         is a tandem pair: too many introns in both to call it anything else\n",
    "        cursor.execute('UPDATE paralogy SET retro = \"F\" WHERE id == ? AND para == ?', (i,p))\n",
    "    \n",
    "\n",
    "    if doneCount % 1000 == 0:\n",
    "        print(doneCount, round(time.time()-startTime,2))\n",
    "        print(syntenyCases)\n",
    "        db.commit()\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting into duplicate categories\n",
    "cursor.execute('ALTER TABLE gene_features ADD COLUMN dupCat_2010 TEXT')\n",
    "cursor.execute('ALTER TABLE gene_features ADD COLUMN dupCat_singh1 TEXT')\n",
    "cursor.execute('ALTER TABLE gene_features ADD COLUMN dupCat_singh2 TEXT')\n",
    "cursor.execute('ALTER TABLE gene_features ADD COLUMN dupCat_singh3 TEXT')\n",
    "cursor.execute('ALTER TABLE gene_features ADD COLUMN dupCat_2020 TEXT')\n",
    "\n",
    "# cursor.execute('UPDATE gene_features SET dupCat_2010 = ?',(None,))\n",
    "# cursor.execute('UPDATE gene_features SET dupCat_singh1 = ?',(None,))\n",
    "# cursor.execute('UPDATE gene_features SET dupCat_singh2 = ?',(None,))\n",
    "# cursor.execute('UPDATE gene_features SET dupCat_singh3 = ?',(None,))\n",
    "# cursor.execute('UPDATE gene_features SET dupCat_2020 = ?',(None,))\n",
    "\n",
    "count = 0\n",
    "t = time.time()\n",
    "\n",
    "# cursor.execute('CREATE INDEX gene ON gene_features(id)')\n",
    "cursor.execute('SELECT id FROM gene_features WHERE dupCat_2020 IS NULL')\n",
    "idList = [x[0] for x in cursor.fetchall()]\n",
    "for i in idList:\n",
    "    count += 1\n",
    "    #fetch ohnolog/singleton/retro/preVert status\n",
    "    cursor.execute('SELECT ohno_2010, ohno_singh_1, ohno_singh2, ohno_sing3, ohno_2020, singleton,retro, preVertebrata FROM paralogy WHERE id == ?', (i,))\n",
    "    res = cursor.fetchall()\n",
    "    \n",
    "    ohno2010Res = [(x[0],x[7]) for x in res]\n",
    "    ohnoS1Res = [(x[1],x[7]) for x in res]\n",
    "    ohnoS2Res = [(x[2],x[7]) for x in res]\n",
    "    ohnoS3Res = [(x[3],x[7]) for x in res]\n",
    "    ohno2020Res = [(x[4],x[7]) for x in res]\n",
    "    singRes = [x[5] for x in res]\n",
    "    retroRes = [x[6] for x in res]\n",
    "    \n",
    "# Initial check for singletons and then classify depending on the types of duplications the gene is involved in\n",
    "\n",
    "    if 'T' in set(singRes):\n",
    "#         singleton\n",
    "        cursor.execute('UPDATE gene_features SET dupCat_2010 = \"singleton\" WHERE id == ?',(i,))\n",
    "        cursor.execute('UPDATE gene_features SET dupCat_singh1 = \"singleton\" WHERE id == ?',(i,))\n",
    "        cursor.execute('UPDATE gene_features SET dupCat_singh2 = \"singleton\" WHERE id == ?',(i,))\n",
    "        cursor.execute('UPDATE gene_features SET dupCat_singh3 = \"singleton\" WHERE id == ?',(i,))\n",
    "        cursor.execute('UPDATE gene_features SET dupCat_2020 = \"singleton\" WHERE id == ?',(i,))\n",
    "        \n",
    "        continue\n",
    "\n",
    "    \n",
    "    for data, col in [(ohno2010Res,'dupCat_2010'),(ohnoS1Res,'dupCat_singh1'),\n",
    "                      (ohnoS2Res,'dupCat_singh2'),(ohnoS3Res,'dupCat_singh3'),\n",
    "                      (ohno2020Res, 'dupCat_2020')]:\n",
    "        if all([x == ('F','T') for x in data]): #all dups are pre-Vert and not ohnos:\n",
    "            cursor.execute('UPDATE gene_features SET '+col+' = \"Singleton (Vert)\" WHERE id== ?',(i,))\n",
    "            continue\n",
    "        #at this point I can probably just keep ohnologs and Vert lineage SSDs?\n",
    "        data = [x[0] for x in data if (x[0] == 'T') or (x[1] == 'F')]\n",
    "        if ('T' in set(data)) and ('F' in set(data)): # mix of ohno and SSD\n",
    "            if 'T' in set(retroRes): #check if there are any retros in with the ohnologs before assigning as mixed\n",
    "                cursor.execute('UPDATE gene_features SET '+col+' = \"mix-retros\" WHERE id== ?',(i,))\n",
    "            else:\n",
    "                cursor.execute('UPDATE gene_features SET '+col+' = \"mix\" WHERE id == ?',(i,))\n",
    "        elif not ('F' in set(data)):\n",
    "            # pure ohnolog\n",
    "            cursor.execute('UPDATE gene_features SET '+col+' = \"WGD\" WHERE id == ?', (i,))\n",
    "        # no ohnologs, check if any retro/inconclusive\n",
    "        elif not ('T' in set(data)):\n",
    "            if (not 'T' in set(retroRes)) and (not 'I' in set(retroRes)): #no retro dups or inconclusive ones\n",
    "                cursor.execute('UPDATE gene_features SET '+col+' = \"SSD\" WHERE id == ?', (i,))\n",
    "            elif (not 'F' in set(retroRes)) and (not 'I' in set(retroRes)): #all the duplications are retro dups\n",
    "                cursor.execute('UPDATE gene_features SET '+col+' = \"Retrogene\" WHERE id == ?', (i,))\n",
    "            else: #a mixture of SSDs and retro dups/inconclusive \n",
    "                cursor.execute('UPDATE gene_features SET '+col+' = \"mix - no ohnos\" WHERE id == ?', (i,))\n",
    "      \n",
    "    if count % 500 ==  0:\n",
    "        print(count, round(time.time()-t,2))\n",
    "        \n",
    "db.commit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#integrating all datasets 2010, Singh relaxed and current\n",
    "#majority rules and unanimous columns\n",
    "cursor.execute('ALTER TABLE gene_features ADD COLUMN dupCat_maj TEXT')\n",
    "cursor.execute('ALTER TABLE gene_features ADD COLUMN dupCat_all TEXT')\n",
    "incCols = ','.join(['dupCat_2010','dupCat_singh1','dupCat_2020_8'])\n",
    "cursor.execute('SELECT id, ' + incCols + ' FROM gene_features')\n",
    "for res in cursor.fetchall():\n",
    "    i = res[0]\n",
    "    dupCats = res[1:]\n",
    "    maj = Counter(dupCats).most_common(1)[0][0]\n",
    "    cursor.execute('UPDATE gene_features SET dupCat_maj = ? WHERE id == ?',(maj,i))\n",
    "    if len(set(dupCats)) == 1: #all cols agree on one category\n",
    "        cursor.execute('UPDATE gene_features SET dupCat_all = ? WHERE id == ?',(dupCats[0],i))\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplicate age assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age assignment - maybe do node and dS\n",
    "# then need to assign numeric values for the nodes\n",
    "# dict of lists for each feature\n",
    "# featureListsDict = {'glen' :[[],[]],\n",
    "\n",
    "# dict of age estimates for divergence times\n",
    "nodeDivAge = {'Opisthokonta':1105/50,\n",
    "             'Bilateria':824/50,\n",
    "             'Chordata':684/50,\n",
    "             'Vertebrata':615/50,\n",
    "             'Gnathostomata':473/50,\n",
    "             'Euteleostomi':435/50,\n",
    "             'Sarcopterygii':413/50,\n",
    "             'Tetrapoda':352/50,\n",
    "             'Amniota':312/50,\n",
    "             'Mammalia':177/50,\n",
    "             'Theria':159/50,\n",
    "             'Eutheria':105/50,\n",
    "             'Boreoeutheria':96/50,\n",
    "             'Euarchontoglires':90/50,\n",
    "             'Primates':74/50,\n",
    "             'Haplorrhini':67/50,\n",
    "             'Simiiformes':43/50,\n",
    "             'Catarrhini':29.4/50,\n",
    "             'Hominoidea':20.2/50,\n",
    "             'Hominidae':16.8/50,\n",
    "             'Homininae':9.1/50,\n",
    "             'Homo sapiens':6.7/50}\n",
    "\n",
    "# select all genes that have vertebrate duplications\n",
    "cursor.execute('ALTER TABLE gene_features ADD COLUMN youngestNode TEXT')\n",
    "cursor.execute('ALTER TABLE gene_features ADD COLUMN oldestNode TEXT')\n",
    "cursor.execute('ALTER TABLE gene_features ADD COLUMN youngestdS REAL')\n",
    "cursor.execute('ALTER TABLE gene_features ADD COLUMN oldestdS REAL')\n",
    "cursor.execute('SELECT id FROM gene_features WHERE dupCat_2010 != \"singleton\"')\n",
    "idList = [x[0] for x in cursor.fetchall()]\n",
    "for i in idList:\n",
    "    cursor.execute('SELECT age,dS FROM paralogy WHERE id == ?',(i,)) \n",
    "    res = cursor.fetchall()\n",
    "    dupAgeList = [x[0] for x in res]\n",
    "    dupDsList = [x[1] for x in res if x[1] != '']\n",
    "    try:\n",
    "        youngestDS = min(dupDsList)\n",
    "        youngestNode = min(dupAgeList, key = lambda x: nodeDivAge[x])\n",
    "        oldestNode = max(dupAgeList, key = lambda x: nodeDivAge[x])\n",
    "        oldestDS = max(dupDsList)\n",
    "        cursor.execute('UPDATE gene_features SET youngestdS = ?, oldestdS = ?, youngestNode = ?, oldestNode = ? WHERE id == ?',(youngestDS, oldestDS, youngestNode,oldestNode,i))\n",
    "    except ValueError:\n",
    "        youngestDS = None\n",
    "        youngestNode = min(dupAgeList, key = lambda x: nodeDivAge[x])\n",
    "        oldestNode = max(dupAgeList, key = lambda x: nodeDivAge[x])\n",
    "        oldestDS = None\n",
    "        cursor.execute('UPDATE gene_features SET youngestdS = ?, oldestdS = ?, youngestNode = ?, oldestNode = ? WHERE id == ?',(youngestDS, oldestDS, youngestNode,oldestNode,i))\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pairwise comparisons and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for grabbing data from database for each feature\n",
    "def getData(feature, dupCat,dupData, transform=None, Filter = None):\n",
    "    from math import log10\n",
    "    if not Filter and dupCat == '\"singleton\"':\n",
    "        query = 'SELECT ' + feature + ' FROM gene_features WHERE (' + dupData + ' == \"singleton\" OR '+ dupData + ' == \"Singleton (Vert)\") AND NOT ' + feature + ' IS NULL'\n",
    "    elif not Filter:\n",
    "        query = 'SELECT ' + feature + ' FROM gene_features WHERE ' + dupData + ' == ' + dupCat + ' AND NOT ' + feature + ' IS NULL' \n",
    "    elif dupCat == '\"singleton\"':\n",
    "        query = 'SELECT ' + feature + ' FROM gene_features WHERE (' + dupData + ' == \"singleton\" OR '+ dupData +' == \"Singleton (Vert)\") AND NOT ' + feature + ' IS NULL AND ' + Filter\n",
    "    else:\n",
    "        query = 'SELECT ' + feature + ' FROM gene_features WHERE ' + dupData +' == ' + dupCat + ' AND ' + Filter\n",
    "#     print(query)\n",
    "    cursor.execute(query)\n",
    "    res1 = [x[0] for x in cursor.fetchall()]\n",
    "    if transform == 'log10':\n",
    "        res = [log10(x) for x in res1]\n",
    "    elif transform == 'log10_zeroes':\n",
    "        res = [log10(x+(min([y for y in res1 if y > 0]))/2) for x in res1]\n",
    "    elif transform == 'neg':\n",
    "        res = [-x for x in res1]\n",
    "    elif transform == 'percent':\n",
    "        res = [x*100 for x in res1]\n",
    "    elif not transform:\n",
    "        res = res1\n",
    "    else:\n",
    "        raise ValueError('Transform \"'+transform+'\" is not defined')\n",
    "    return [x for x in res if x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generic plotting code\n",
    "fig, ax = plt.subplots(1,1,figsize = (10,10))\n",
    "data = np.linspace(1,100,num=30)\n",
    "data2 = np.linspace(50,100,num=30)\n",
    "data3 = np.linspace(1,75,num=30)\n",
    "data4 = np.linspace(25,75,num=30)\n",
    "box = ax.boxplot([data,data2, data3,data4],labels=['WGD','Mixed','SSD','Singleton'],patch_artist=True)\n",
    "ax.yaxis.set_tick_params(labelsize=16)\n",
    "ax.xaxis.set_tick_params(labelsize=16)\n",
    "bCount = 0\n",
    "for b in box['boxes']:\n",
    "    bCount += 1\n",
    "    if bCount ==1:\n",
    "        b.set_facecolor((0.9,0.2,0,0.7))\n",
    "    if bCount == 2:\n",
    "        b.set_facecolor((0.9,0.3,0,0.4))\n",
    "    if bCount == 3:\n",
    "        b.set_facecolor((1,0.41,0,0.2))\n",
    "        bCount = 0\n",
    "    b.set_ec('k')\n",
    "for m in box['medians']:\n",
    "    m.set_lw(2)\n",
    "    m.set_color('k')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.xaxis.set_ticks_position('none') \n",
    "ax.plot([1,1.95],[110,110],lw=1,color='k',zorder=1)\n",
    "ax.plot([2.05,2.95],[110,110],lw=1,color='k',zorder=1)\n",
    "ax.plot([3.05,4],[110,110],lw=1,color='k',zorder=1)\n",
    "ax.plot([1,3],[120,120],lw=1,color='k',zorder=1)\n",
    "ax.plot([2,4],[130,130],lw=1,color='k',zorder=1)\n",
    "ax.plot([1,4],[140,140],lw=1,color='k',zorder=1)\n",
    "ax.scatter([1,1.95,2.05,2.95,3.05,4,1,3,2,4,1,4],[110,110,110,110,110,110,120,120,130,130,140,140],color=(0.8,0,0,1),s=30,zorder=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting: seq and structural features\n",
    "#trying without the 'mixed' category\n",
    "def scale_lightness(rgb, scale_l):\n",
    "    # convert rgb to hls\n",
    "    h, l, s = colorsys.rgb_to_hls(*rgb)\n",
    "    # manipulate h, l, s values and return as rgb\n",
    "    return colorsys.hls_to_rgb(h, min(1, l * scale_l), s = s)\n",
    "def formatPval(list1,list2,correction):\n",
    "    pval = (mannwhitneyu(list1,list2,alternative='two-sided').pvalue)*correction\n",
    "    if pval >= 0.05:\n",
    "        return 'ns'\n",
    "    elif pval >= 0.001:\n",
    "        return round(pval,3)\n",
    "    else:\n",
    "        valList = '{:.2e}'.format(pval).split('e')\n",
    "        return valList[0]+'x 10$^{-'+valList[1].lstrip('-').lstrip('0')+'}$'\n",
    "colUsed = 'dupCat_maj'\n",
    "featList = ['genLen','cdsLen','intCount','intAvg',\n",
    "                'intCov','CAI','IntDisProp','gc',\n",
    "                'gc3','domains','u_domains']\n",
    "namesDict = {'genLen':('Genomic Length','log(bp)'),'cdsLen':('CDS Length','log(bp)'),'intCount':('Intron Count','log(count)'),\n",
    "             'intAvg':('Mean intron length','log(bp)'),'intCov':('Intron coverage','%'),'CAI':('Codon optimisation','CAI score'),\n",
    "             'IntDisProp':('Intrinsic Disorder','%'),'gc':('GC content','%'),'gc3':('GC3 content','%'),\n",
    "             'domains':('Total domains','log(count)'),'u_domains':('Unique domains','count')}\n",
    "featDict = {}\n",
    "for feature in featList:\n",
    "    featDict[feature] = {}\n",
    "    if feature == 'genLen' or feature == 'cdsLen' or feature == 'intAvg':\n",
    "        featDict[feature]['WGD'] = getData(feature, '\"WGD\"',colUsed,transform='log10')\n",
    "        featDict[feature]['SSD'] = getData(feature, '\"SSD\"',colUsed,transform='log10')\n",
    "#         featDict[feature]['Mix'] = getData(feature, '\"mix\"',colUsed,transform='log10')\n",
    "        featDict[feature]['Singleton'] = getData(feature, '\"singleton\"',colUsed,transform='log10')\n",
    "    elif feature == 'intCount' or feature == 'domains':\n",
    "        featDict[feature]['WGD'] = getData(feature, '\"WGD\"',colUsed,transform='log10_zeroes')\n",
    "        featDict[feature]['SSD'] = getData(feature, '\"SSD\"',colUsed,transform='log10_zeroes')\n",
    "#         featDict[feature]['Mix'] = getData(feature, '\"mix\"',colUsed,transform='log10')\n",
    "        featDict[feature]['Singleton'] = getData(feature, '\"singleton\"',colUsed,transform='log10_zeroes')\n",
    "    elif feature == 'CAI':\n",
    "        featDict[feature]['WGD'] = getData(feature, '\"WGD\"',colUsed,Filter='CAI != \"Error-check\"')\n",
    "        featDict[feature]['SSD'] = getData(feature, '\"SSD\"',colUsed,Filter='CAI != \"Error-check\"')\n",
    "#         featDict[feature]['Mix'] = getData(feature, '\"mix\"',colUsed,Filter='CAI != \"Error-check\"')\n",
    "        featDict[feature]['Singleton'] = getData(feature, '\"singleton\"',colUsed,Filter='CAI != \"Error-check\"')\n",
    "    elif feature == 'IntDisProp' or feature == 'intCov':\n",
    "        featDict[feature]['WGD'] = getData(feature, '\"WGD\"',colUsed,transform='percent')\n",
    "        featDict[feature]['SSD'] = getData(feature, '\"SSD\"',colUsed,transform='percent')\n",
    "#         featDict[feature]['Mix'] = getData(feature, '\"mix\"',colUsed,transform='log10')\n",
    "        featDict[feature]['Singleton'] = getData(feature, '\"singleton\"',colUsed,transform='percent')\n",
    "    else:\n",
    "        featDict[feature]['WGD'] = getData(feature, '\"WGD\"',colUsed)\n",
    "        featDict[feature]['SSD'] = getData(feature, '\"SSD\"',colUsed)\n",
    "#         featDict[feature]['Mix'] = getData(feature, '\"mix\"',colUsed)\n",
    "        featDict[feature]['Singleton'] = getData(feature, '\"singleton\"',colUsed)\n",
    "        \n",
    "fig, axes = plt.subplots(4,3,figsize = (17,20))\n",
    "flatAx = []\n",
    "for axList in axes:\n",
    "    flatAx.extend(axList)\n",
    "for feature, ax in zip(featList,flatAx):\n",
    "    if feature == 'intCount_b' or feature == 'domains_b':\n",
    "        dataList = [featDict[feature]['WGD'],featDict[feature]['SSD'],featDict[feature]['Singleton']]\n",
    "        maxVal = max([max(x) for x in dataList])\n",
    "        minVal = min([min(x) for x in dataList])\n",
    "        if feature == 'intCount':\n",
    "            max2, min2 = 205, 340\n",
    "        elif feature == 'domains':\n",
    "            max2, min2 = 105,310\n",
    "        valRange = (maxVal-minVal) - (min2-max2)\n",
    "        divider = make_axes_locatable(ax)\n",
    "        perCentSize = str((((maxVal + 2.3*(valRange/5))-min2)/(max2-minVal))*100)+'%'\n",
    "        ax2 = divider.new_vertical(size=perCentSize,pad='3%')\n",
    "        fig.add_axes(ax2)\n",
    "        for a in [ax,ax2]:\n",
    "            box = a.boxplot(dataList,labels=['WGD','SSD','Singleton'],patch_artist=True,flierprops={'ms':1})\n",
    "            a.yaxis.set_tick_params(labelsize=14)\n",
    "            a.xaxis.set_tick_params(labelsize=14)\n",
    "            bCount = 0\n",
    "            for b in box['boxes']:\n",
    "                bCount += 1\n",
    "                if bCount ==1:\n",
    "                    b.set_facecolor(scale_lightness((0.9,0.2,0),1.4))\n",
    "                if bCount == 2:\n",
    "                    b.set_facecolor(scale_lightness((0.9,0.3,0),1.8))\n",
    "                if bCount == 3:\n",
    "                    b.set_facecolor(scale_lightness((1,0.41,0),1.8))\n",
    "                    bCount = 0\n",
    "                b.set_ec('k')\n",
    "            for m in box['medians']:\n",
    "                m.set_lw(2)\n",
    "                m.set_color('k')\n",
    "            a.spines['top'].set_visible(False)\n",
    "            a.spines['right'].set_visible(False)\n",
    "            a.spines['bottom'].set_visible(False)\n",
    "            a.xaxis.set_ticks_position('none') \n",
    "            a.plot([0.95,1.95],[maxVal + 0.9*(valRange/5),maxVal+0.9*(valRange/5)],lw=1,color='k',zorder=2)\n",
    "            a.plot([2.05,3.05],[maxVal + 0.9*(valRange/5),maxVal+0.9*(valRange/5)],lw=1,color='k',zorder=2)\n",
    "            #a.plot([3.05,4],[maxVal + valRange/5,maxVal+valRange/5],lw=1,color='k',zorder=2)\n",
    "            a.plot([0.95,3.05],[maxVal + 2.1*(valRange/5),maxVal+2.1*(valRange/5)],lw=1,color='k',zorder=2)\n",
    "            #a.plot([2,4],[maxVal + 3*(valRange/5),maxVal+3*(valRange/5)],lw=1,color='k',zorder=2)\n",
    "            #a.plot([1,4],[maxVal + 4*(valRange/5),maxVal+4*(valRange/5)],lw=1,color='k',zorder=2)\n",
    "            a.scatter([0.95,1.95,2.05,3.05,0.95,3.05],[maxVal+0.9*(valRange/5),maxVal+0.9*(valRange/5),\n",
    "                                            maxVal+0.9*(valRange/5),maxVal+0.9*(valRange/5),\n",
    "                                            maxVal +2.1*(valRange/5),maxVal+2.1*(valRange/5)],color=(0.8,0,0,1),s=30,zorder=3)\n",
    "        #pvals\n",
    "        ax2.text(1.45,maxVal + 1.1*(valRange/5),formatPval(dataList[0],dataList[1],len(featList)*3),fontsize=14,ha='center')\n",
    "        ax2.text(2.55,maxVal + 1.1*(valRange/5),formatPval(dataList[1],dataList[2],len(featList)*3),fontsize=14,ha='center')\n",
    "        #ax2.text(3.5,maxVal + 1.1*(valRange/5),formatPval(dataList[2],dataList[3],len(featList)*4),fontsize=14,ha='center')\n",
    "        ax2.text(2,maxVal + 2.3*(valRange/5),formatPval(dataList[0],dataList[2],len(featList)*3),fontsize=14,ha='center')\n",
    "#         ax2.text(3,maxVal + 3.1*(valRange/5),formatPval(dataList[1],dataList[3],len(featList)*4),fontsize=14,ha='center')\n",
    "#         ax2.text(2.5,maxVal + 4.1*(valRange/5),formatPval(dataList[0],dataList[3],len(featList)*4),fontsize=14,ha='center')\n",
    "       \n",
    "        ax.set_xlabel(namesDict[feature][0],fontsize=16)\n",
    "        ax.yaxis.set_label_coords(-0.12, 0.8)\n",
    "        ax.set_ylim(ymin=0,ymax=max2)\n",
    "        ax.set_ylabel(namesDict[feature][1],fontsize=16)\n",
    "        ax.set_facecolor((0,0,0,0.05))\n",
    "        ax.grid(color='w',lw=2)\n",
    "        ax2.set_facecolor((0,0,0,0.05))\n",
    "        ax2.grid(color='w',lw=2)\n",
    "        ax2.vlines(x=1,color='w',lw=2,ymin=ax2.get_ylim()[0],ymax=ax2.get_ylim()[1])\n",
    "        ax2.vlines(x=2,color='w',lw=2,ymin=ax2.get_ylim()[0],ymax=ax2.get_ylim()[1])\n",
    "        ax2.vlines(x=3,color='w',lw=2,ymin=ax2.get_ylim()[0],ymax=ax2.get_ylim()[1])\n",
    "#         ax2.vlines(x=4,color='w',lw=2,ymin=ax2.get_ylim()[0],ymax=ax2.get_ylim()[1])\n",
    "        ax2.set_ylim(ymin=min2,ymax=maxVal+3*(valRange/5))\n",
    "#         ax2.tick_params(bottom=\"off\", labelbottom='off')\n",
    "        ax2.xaxis.set_visible(False)\n",
    "# data = np.linspace(1,100,num=30)\n",
    "# data2 = np.linspace(50,100,num=30)\n",
    "# data3 = np.linspace(1,75,num=30)\n",
    "    else:\n",
    "        dataList = [featDict[feature]['WGD'],featDict[feature]['SSD'],featDict[feature]['Singleton']]\n",
    "        maxVal = max([max(x) for x in dataList])\n",
    "        minVal = min([min(x) for x in dataList])\n",
    "        valRange = maxVal-minVal\n",
    "        box = ax.boxplot(dataList,labels=['WGD','SSD','Singleton'],patch_artist=True,flierprops={'ms':1})\n",
    "        ax.yaxis.set_tick_params(labelsize=14)\n",
    "        ax.xaxis.set_tick_params(labelsize=14)\n",
    "        bCount = 0\n",
    "        for b in box['boxes']:\n",
    "            bCount += 1\n",
    "            if bCount ==1:\n",
    "                #b.set_facecolor((0.9,0.2,0,0.7))\n",
    "                b.set_facecolor(scale_lightness((0.9,0.2,0),1.4))\n",
    "            if bCount == 2:\n",
    "                #b.set_facecolor((0.9,0.3,0,0.4))\n",
    "                b.set_facecolor(scale_lightness((0.9,0.3,0),1.8))\n",
    "            if bCount == 3:\n",
    "#                 b.set_facecolor((1,0.41,0,0.2))\n",
    "                b.set_facecolor(scale_lightness((1,0.41,0),1.8))\n",
    "                bCount = 0\n",
    "            b.set_ec('k')\n",
    "        for m in box['medians']:\n",
    "            m.set_lw(2)\n",
    "            m.set_color('k')\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['bottom'].set_visible(False)\n",
    "        ax.xaxis.set_ticks_position('none') \n",
    "        ax.plot([0.95,1.95],[maxVal + 1.1*(valRange/5),maxVal+1.1*(valRange/5)],lw=1,color='k',zorder=2)\n",
    "        ax.plot([2.05,3.05],[maxVal + 1.1*(valRange/5),maxVal+1.1*(valRange/5)],lw=1,color='k',zorder=2)\n",
    "#         ax.plot([3.05,4],[maxVal + valRange/5,maxVal+valRange/5],lw=1,color='k',zorder=2)\n",
    "        ax.plot([0.95,3.05],[maxVal + 2.2*(valRange/5),maxVal+2.2*(valRange/5)],lw=1,color='k',zorder=2)\n",
    "#         ax.plot([2,4],[maxVal + 3*(valRange/5),maxVal+3*(valRange/5)],lw=1,color='k',zorder=2)\n",
    "#         ax.plot([1,4],[maxVal + 4*(valRange/5),maxVal+4*(valRange/5)],lw=1,color='k',zorder=2)\n",
    "        ax.scatter([0.95,1.95,2.05,3.05,0.95,3.05],[maxVal+1.1*(valRange/5),maxVal+1.1*(valRange/5),\n",
    "                                            maxVal+1.1*(valRange/5),maxVal+1.1*(valRange/5),\n",
    "                                            maxVal + 2.2*(valRange/5),maxVal+2.2*(valRange/5)],color=(0.8,0,0,1),s=30,zorder=3)\n",
    "        #pvals\n",
    "        ax.text(1.45,maxVal + 1.3*(valRange/5),formatPval(dataList[0],dataList[1],len(featList)*3),fontsize=14,ha='center')\n",
    "        ax.text(2.55,maxVal + 1.3*(valRange/5),formatPval(dataList[1],dataList[2],len(featList)*3),fontsize=14,ha='center')\n",
    "#         ax.text(3.5,maxVal + 1.1*(valRange/5),formatPval(dataList[2],dataList[3],len(featList)*4),fontsize=14,ha='center')\n",
    "        ax.text(2,maxVal + 2.4*(valRange/5),formatPval(dataList[0],dataList[2],len(featList)*3),fontsize=14,ha='center')\n",
    "#         ax.text(3,maxVal + 3.1*(valRange/5),formatPval(dataList[1],dataList[3],len(featList)*4),fontsize=14,ha='center')\n",
    "#         ax.text(2.5,maxVal + 4.1*(valRange/5),formatPval(dataList[0],dataList[3],len(featList)*4),fontsize=14,ha='center')\n",
    "       \n",
    "        ax.set_xlabel(namesDict[feature][0],fontsize=16)\n",
    "        ax.set_ylabel(namesDict[feature][1],fontsize=16)\n",
    "        \n",
    "        ax.set_ylim(ymax=maxVal+3*(valRange/5))\n",
    "        \n",
    "        ax.set_facecolor((0,0,0,0.05))\n",
    "        ax.grid(color='w',lw=2,zorder=0)\n",
    "        #     if feature == 'cdsLen':\n",
    "#         break\n",
    "flatAx[-1].set_visible(False)\n",
    "plt.savefig('BOXPLOTS_PAIRWISE/final_seqStruc'+colUsed+'.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting: reg features , no mix\n",
    "def scale_lightness(rgb, scale_l):\n",
    "    # convert rgb to hls\n",
    "    h, l, s = colorsys.rgb_to_hls(*rgb)\n",
    "    # manipulate h, l, s values and return as rgb\n",
    "    return colorsys.hls_to_rgb(h, min(1, l * scale_l), s = s)\n",
    "def formatPval(list1,list2,correction):\n",
    "    pval = (mannwhitneyu(list1,list2,alternative='two-sided').pvalue)*correction\n",
    "    if pval >= 0.05:\n",
    "        return 'ns'\n",
    "    elif pval >= 0.001:\n",
    "        return round(pval,3)\n",
    "    else:\n",
    "        valList = '{:.2e}'.format(pval).split('e')\n",
    "        return valList[0]+'x 10$^{-'+valList[1].lstrip('-').lstrip('0')+'}$'\n",
    "colUsed = 'dupCat_maj'\n",
    "featList = ['max_exp','specificity','transCount','motif_number_1k','PPIs']\n",
    "namesDict = {'max_exp':('Maximal expression','log(TPM)'),'specificity':('Expression specificity','tau'),\n",
    "             'transCount':('Number of isoforms','count'),'motif_number_1k':('Number of regulatory motifs','count'),\n",
    "             'PPIs':('PPIs','log(count)')}\n",
    "featDict = {}\n",
    "for feature in featList:\n",
    "    featDict[feature] = {}\n",
    "    if feature == 'max_exp' or feature == 'PPIs':\n",
    "        featDict[feature]['WGD'] = getData(feature, '\"WGD\"',colUsed,transform='log10_zeroes')\n",
    "        featDict[feature]['SSD'] = getData(feature, '\"SSD\"',colUsed,transform='log10_zeroes')\n",
    "#         featDict[feature]['Mix'] = getData(feature, '\"mix\"',colUsed,transform='log10')\n",
    "        featDict[feature]['Singleton'] = getData(feature, '\"singleton\"',colUsed,transform='log10_zeroes')\n",
    "    elif feature == 'CAI':\n",
    "        featDict[feature]['WGD'] = getData(feature, '\"WGD\"',colUsed,Filter='CAI != \"Error-check\"')\n",
    "        featDict[feature]['SSD'] = getData(feature, '\"SSD\"',colUsed,Filter='CAI != \"Error-check\"')\n",
    "#         featDict[feature]['Mix'] = getData(feature, '\"mix\"',colUsed,Filter='CAI != \"Error-check\"')\n",
    "        featDict[feature]['Singleton'] = getData(feature, '\"singleton\"',colUsed,Filter='CAI != \"Error-check\"')\n",
    "    else:\n",
    "        featDict[feature]['WGD'] = getData(feature, '\"WGD\"',colUsed)\n",
    "        featDict[feature]['SSD'] = getData(feature, '\"SSD\"',colUsed)\n",
    "#         featDict[feature]['Mix'] = getData(feature, '\"mix\"',colUsed)\n",
    "        featDict[feature]['Singleton'] = getData(feature, '\"singleton\"',colUsed)\n",
    "        \n",
    "fig, axes = plt.subplots(2,3,figsize = (17,10))\n",
    "flatAx = []\n",
    "for axList in axes:\n",
    "    flatAx.extend(axList)\n",
    "for feature, ax in zip(featList,flatAx):\n",
    "    if feature == 'PPIs-b':\n",
    "        dataList = [featDict[feature]['WGD'],featDict[feature]['SSD'],featDict[feature]['Singleton']]\n",
    "        maxVal = max([max(x) for x in dataList])\n",
    "        minVal = min([min(x) for x in dataList])\n",
    "        max2, min2 = 350, 450\n",
    "        valRange = (maxVal-minVal) - (min2-max2)\n",
    "        divider = make_axes_locatable(ax)\n",
    "        perCentSize = str((((maxVal + 3*(valRange/5))-min2)/(max2-minVal))*100)+'%'\n",
    "        ax2 = divider.new_vertical(size=perCentSize,pad='4%')\n",
    "        fig.add_axes(ax2)\n",
    "        for a in [ax,ax2]:\n",
    "            box = a.boxplot(dataList,labels=['WGD','SSD','Singleton'],patch_artist=True,flierprops={'ms':1})\n",
    "            a.yaxis.set_tick_params(labelsize=14)\n",
    "            a.xaxis.set_tick_params(labelsize=14)\n",
    "            bCount = 0\n",
    "            for b in box['boxes']:\n",
    "                bCount += 1\n",
    "                if bCount ==1:\n",
    "                    b.set_facecolor(scale_lightness((0.9,0.2,0),1.4))\n",
    "                if bCount == 2:\n",
    "                    b.set_facecolor(scale_lightness((0.9,0.3,0),1.8))\n",
    "                if bCount == 3:\n",
    "                    b.set_facecolor(scale_lightness((1,0.41,0),1.8))\n",
    "                    bCount = 0\n",
    "                b.set_ec('k')\n",
    "            for m in box['medians']:\n",
    "                m.set_lw(2)\n",
    "                m.set_color('k')\n",
    "            a.spines['top'].set_visible(False)\n",
    "            a.spines['right'].set_visible(False)\n",
    "            a.spines['bottom'].set_visible(False)\n",
    "            a.xaxis.set_ticks_position('none') \n",
    "            a.plot([0.95,1.95],[maxVal + 1.1*(valRange/5),maxVal+1.1*(valRange/5)],lw=1,color='k',zorder=2)\n",
    "            a.plot([2.05,3.05],[maxVal + 1.1*(valRange/5),maxVal+1.1*(valRange/5)],lw=1,color='k',zorder=2)\n",
    "#             a.plot([3.05,4],[maxVal + valRange/5,maxVal+valRange/5],lw=1,color='k',zorder=2)\n",
    "            a.plot([0.95,3.05],[maxVal + 2.2*(valRange/5),maxVal+2.2*(valRange/5)],lw=1,color='k',zorder=2)\n",
    "#             a.plot([2,4],[maxVal + 3*(valRange/5),maxVal+3*(valRange/5)],lw=1,color='k',zorder=2)\n",
    "#             a.plot([1,4],[maxVal + 4*(valRange/5),maxVal+4*(valRange/5)],lw=1,color='k',zorder=2)\n",
    "            a.scatter([0.95,1.95,2.05,3.05,0.95,3.05],[maxVal+1.1*(valRange/5),maxVal+1.1*(valRange/5),\n",
    "                                                              maxVal+1.1*(valRange/5),maxVal+1.1*(valRange/5),\n",
    "                                                              maxVal + 2.2*(valRange/5),maxVal+2.2*(valRange/5)],color=(0.8,0,0,1),s=30,zorder=3)\n",
    "        #pvals\n",
    "        ax2.text(1.45,maxVal + 1.3*(valRange/5),formatPval(dataList[0],dataList[1],len(featList)*3),fontsize=14,ha='center')\n",
    "        ax2.text(2.55,maxVal + 1.3*(valRange/5),formatPval(dataList[1],dataList[2],len(featList)*3),fontsize=14,ha='center')\n",
    "#         ax2.text(3.5,maxVal + 1.1*(valRange/5),formatPval(dataList[2],dataList[3],len(featList)*4),fontsize=20,ha='center')\n",
    "        ax2.text(2,maxVal + 2.4*(valRange/5),formatPval(dataList[0],dataList[2],len(featList)*3),fontsize=14,ha='center')\n",
    "#         ax2.text(3,maxVal + 3.1*(valRange/5),formatPval(dataList[1],dataList[3],len(featList)*4),fontsize=20,ha='center')\n",
    "#         ax2.text(2.5,maxVal + 4.1*(valRange/5),formatPval(dataList[0],dataList[3],len(featList)*4),fontsize=20,ha='center')\n",
    "       \n",
    "        ax.set_xlabel(namesDict[feature][0],fontsize=14)\n",
    "        ax.yaxis.set_label_coords(-0.12, 0.85)\n",
    "        ax.set_ylim(ymin=0,ymax=max2)\n",
    "        ax.set_ylabel(namesDict[feature][1],fontsize=14)\n",
    "        ax.set_facecolor((0,0,0,0.05))\n",
    "        ax.grid(color='w',lw=2)\n",
    "        ax2.set_facecolor((0,0,0,0.05))\n",
    "        ax2.grid(color='w',lw=2)\n",
    "        ax2.vlines(x=1,color='w',lw=2,ymin=ax2.get_ylim()[0],ymax=ax2.get_ylim()[1])\n",
    "        ax2.vlines(x=2,color='w',lw=2,ymin=ax2.get_ylim()[0],ymax=ax2.get_ylim()[1])\n",
    "        ax2.vlines(x=3,color='w',lw=2,ymin=ax2.get_ylim()[0],ymax=ax2.get_ylim()[1])\n",
    "#         ax2.vlines(x=4,color='w',lw=2,ymin=ax2.get_ylim()[0],ymax=ax2.get_ylim()[1])\n",
    "        ax2.set_ylim(ymin=min2,ymax=maxVal+3*(valRange/5))\n",
    "#         ax2.tick_params(bottom=\"off\", labelbottom='off')\n",
    "        ax2.xaxis.set_visible(False)\n",
    "# data = np.linspace(1,100,num=30)\n",
    "# data2 = np.linspace(50,100,num=30)\n",
    "# data3 = np.linspace(1,75,num=30)\n",
    "    else:\n",
    "        dataList = [featDict[feature]['WGD'],featDict[feature]['SSD'],featDict[feature]['Singleton']]\n",
    "        maxVal = max([max(x) for x in dataList])\n",
    "        minVal = min([min(x) for x in dataList])\n",
    "        valRange = maxVal-minVal\n",
    "        box = ax.boxplot(dataList,labels=['WGD','SSD','Singleton'],patch_artist=True,flierprops={'ms':1})\n",
    "        ax.yaxis.set_tick_params(labelsize=14)\n",
    "        ax.xaxis.set_tick_params(labelsize=14)\n",
    "        bCount = 0\n",
    "        for b in box['boxes']:\n",
    "            bCount += 1\n",
    "            if bCount ==1:\n",
    "                #b.set_facecolor((0.9,0.2,0,0.7))\n",
    "                b.set_facecolor(scale_lightness((0.9,0.2,0),1.4))\n",
    "            if bCount == 2:\n",
    "                #b.set_facecolor((0.9,0.3,0,0.4))\n",
    "                b.set_facecolor(scale_lightness((0.9,0.3,0),1.8))\n",
    "            if bCount == 3:\n",
    "#                 b.set_facecolor((1,0.41,0,0.2))\n",
    "                b.set_facecolor(scale_lightness((1,0.41,0),1.8))\n",
    "                bCount = 0\n",
    "            b.set_ec('k')\n",
    "        for m in box['medians']:\n",
    "            m.set_lw(2)\n",
    "            m.set_color('k')\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['bottom'].set_visible(False)\n",
    "        ax.xaxis.set_ticks_position('none') \n",
    "        ax.plot([0.95,1.95],[maxVal + 1.1*(valRange/5),maxVal+1.1*(valRange/5)],lw=1,color='k',zorder=2)\n",
    "        ax.plot([2.05,3.05],[maxVal + 1.1*(valRange/5),maxVal+1.1*(valRange/5)],lw=1,color='k',zorder=2)\n",
    "#         ax.plot([3.05,4],[maxVal + valRange/5,maxVal+valRange/5],lw=1,color='k',zorder=2)\n",
    "        ax.plot([1,3],[maxVal + 2.2*(valRange/5),maxVal+2.2*(valRange/5)],lw=1,color='k',zorder=2)\n",
    "#         ax.plot([2,4],[maxVal + 3*(valRange/5),maxVal+3*(valRange/5)],lw=1,color='k',zorder=2)\n",
    "#         ax.plot([1,4],[maxVal + 4*(valRange/5),maxVal+4*(valRange/5)],lw=1,color='k',zorder=2)\n",
    "        ax.scatter([0.95,1.95,2.05,3.05,0.95,3.05],[maxVal+1.1*(valRange/5),maxVal+1.1*(valRange/5),\n",
    "                                                          maxVal+1.1*(valRange/5),maxVal+1.1*(valRange/5),\n",
    "                                                          maxVal + 2.2*(valRange/5),maxVal+2.2*(valRange/5)],color=(0.8,0,0,1),s=30,zorder=3)\n",
    "        #pvals\n",
    "        ax.text(1.45,maxVal + 1.3*(valRange/5),formatPval(dataList[0],dataList[1],len(featList)*3),fontsize=14,ha='center')\n",
    "        ax.text(2.55,maxVal + 1.3*(valRange/5),formatPval(dataList[1],dataList[2],len(featList)*3),fontsize=14,ha='center')\n",
    "#         ax.text(3.5,maxVal + 1.1*(valRange/5),formatPval(dataList[2],dataList[3],len(featList)*4),fontsize=14,ha='center')\n",
    "        ax.text(2,maxVal + 2.4*(valRange/5),formatPval(dataList[0],dataList[2],len(featList)*3),fontsize=14,ha='center')\n",
    "#         ax.text(3,maxVal + 3.1*(valRange/5),formatPval(dataList[1],dataList[3],len(featList)*4),fontsize=14,ha='center')\n",
    "#         ax.text(2.5,maxVal + 4.1*(valRange/5),formatPval(dataList[0],dataList[3],len(featList)*4),fontsize=14,ha='center')\n",
    "       \n",
    "        ax.set_xlabel(namesDict[feature][0],fontsize=16)\n",
    "        ax.set_ylabel(namesDict[feature][1],fontsize=16)\n",
    "        \n",
    "        ax.set_facecolor((0,0,0,0.05))\n",
    "        ax.grid(color='w',lw=2,zorder=0)\n",
    "        ax.set_ylim(ymax=maxVal+3*(valRange/5))\n",
    "        #     if feature == 'cdsLen':\n",
    "#         break\n",
    "flatAx[-1].set_visible(False)\n",
    "plt.savefig('BOXPLOTS_PAIRWISE/final_reg_no_mix_'+colUsed+'.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting: constraint features, no mix\n",
    "def scale_lightness(rgb, scale_l):\n",
    "    # convert rgb to hls\n",
    "    h, l, s = colorsys.rgb_to_hls(*rgb)\n",
    "    # manipulate h, l, s values and return as rgb\n",
    "    return colorsys.hls_to_rgb(h, min(1, l * scale_l), s = s)\n",
    "def formatPval(list1,list2,correction):\n",
    "    pval = (mannwhitneyu(list1,list2,alternative='two-sided').pvalue)*correction\n",
    "    if pval >= 0.05:\n",
    "        return 'ns'\n",
    "    elif pval >= 0.001:\n",
    "        return round(pval,3)\n",
    "    else:\n",
    "        valList = '{:.2e}'.format(pval).split('e')\n",
    "        return valList[0]+'x 10$^{-'+valList[1].lstrip('-').lstrip('0')+'}$'\n",
    "colUsed = 'dupCat_maj'\n",
    "featList = ['evolRate','ess','mis_Z_score',\n",
    "            'pLI_score','Phi','s_het',\n",
    "            'EvoTol','loftool_percentile','RVIS']\n",
    "namesDict = {'evolRate':('Rate of evolution','dN/dS'),'ess':('Cellular essentiality','-(CRISPR score)'),\n",
    "             'mis_Z_score':('Missense Z score','score'),'pLI_score':('pLI','score'),'Phi':('Phi','score'),\n",
    "             's_het':('S$_{het}$','score'),'EvoTol':('EvoTol','score'),'loftool_percentile':('LoFTool','percentile'),\n",
    "             'RVIS':('RVIS','score')}\n",
    "featDict = {}\n",
    "for feature in featList:\n",
    "    featDict[feature] = {}\n",
    "    if feature == 'ess':\n",
    "        featDict[feature]['WGD'] = getData(feature, '\"WGD\"',colUsed,transform='neg')\n",
    "        featDict[feature]['SSD'] = getData(feature, '\"SSD\"',colUsed,transform='neg')\n",
    "#         featDict[feature]['Mix'] = getData(feature, '\"mix\"',colUsed,transform='neg')\n",
    "        featDict[feature]['Singleton'] = getData(feature, '\"singleton\"',colUsed,transform='neg')\n",
    "    elif feature == 'pLI_score':\n",
    "        featDict[feature]['WGD'] = getData(feature, '\"WGD\"',colUsed,Filter='pLI_score != \"NA\"')\n",
    "        featDict[feature]['SSD'] = getData(feature, '\"SSD\"',colUsed,Filter='pLI_score != \"NA\"')\n",
    "#         featDict[feature]['Mix'] = getData(feature, '\"mix\"',colUsed,Filter='pLI_score != \"NA\"')\n",
    "        featDict[feature]['Singleton'] = getData(feature, '\"singleton\"',colUsed,Filter='pLI_score != \"NA\"')\n",
    "    elif feature == 'RVIS':\n",
    "        featDict[feature]['WGD'] = getData(feature, '\"WGD\"',colUsed,Filter='RVIS != \"NA\"')\n",
    "        featDict[feature]['SSD'] = getData(feature, '\"SSD\"',colUsed,Filter='RVIS != \"NA\"')\n",
    "#         featDict[feature]['Mix'] = getData(feature, '\"mix\"',colUsed,Filter='RVIS != \"NA\"')\n",
    "        featDict[feature]['Singleton'] = getData(feature, '\"singleton\"',colUsed,Filter='RVIS != \"NA\"')\n",
    "    elif feature == 'EvoTol':\n",
    "        featDict[feature]['WGD'] = getData(feature, '\"WGD\"',colUsed,Filter='EvoTol != \"Not expressed above threshold in this ontology\"')\n",
    "        featDict[feature]['SSD'] = getData(feature, '\"SSD\"',colUsed,Filter='EvoTol != \"Not expressed above threshold in this ontology\"')\n",
    "#         featDict[feature]['Mix'] = getData(feature, '\"mix\"',colUsed,Filter='EvoTol != \"Not expressed above threshold in this ontology\"')\n",
    "        featDict[feature]['Singleton'] = getData(feature, '\"singleton\"',colUsed,Filter='EvoTol != \"Not expressed above threshold in this ontology\"')\n",
    "    else:\n",
    "        featDict[feature]['WGD'] = getData(feature, '\"WGD\"',colUsed)\n",
    "        featDict[feature]['SSD'] = getData(feature, '\"SSD\"',colUsed)\n",
    "#         featDict[feature]['Mix'] = getData(feature, '\"mix\"',colUsed)\n",
    "        featDict[feature]['Singleton'] = getData(feature, '\"singleton\"',colUsed)\n",
    "        \n",
    "fig, axes = plt.subplots(3,3,figsize = (17,15))\n",
    "flatAx = []\n",
    "for axList in axes:\n",
    "    flatAx.extend(axList)\n",
    "for feature, ax in zip(featList,flatAx):\n",
    "    if feature == 'PPIs':\n",
    "        dataList = [featDict[feature]['WGD'],featDict[feature]['Mix'],featDict[feature]['SSD'],featDict[feature]['Singleton']]\n",
    "        maxVal = max([max(x) for x in dataList])\n",
    "        minVal = min([min(x) for x in dataList])\n",
    "        max2, min2 = 350, 450\n",
    "        valRange = (maxVal-minVal) - (min2-max2)\n",
    "        divider = make_axes_locatable(ax)\n",
    "        perCentSize = str((((maxVal + 4.3*(valRange/5))-min2)/(max2-minVal))*100)+'%'\n",
    "        ax2 = divider.new_vertical(size=perCentSize,pad='3%')\n",
    "        fig.add_axes(ax2)\n",
    "        for a in [ax,ax2]:\n",
    "            box = a.boxplot(dataList,labels=['WGD','SSD','Singleton'],patch_artist=True,flierprops={'ms':1})\n",
    "            a.yaxis.set_tick_params(labelsize=20)\n",
    "            a.xaxis.set_tick_params(labelsize=22)\n",
    "            bCount = 0\n",
    "            for b in box['boxes']:\n",
    "                bCount += 1\n",
    "                if bCount ==1:\n",
    "                    b.set_facecolor(scale_lightness((0.9,0.2,0),1.4))\n",
    "                if bCount == 2:\n",
    "                    b.set_facecolor(scale_lightness((0.9,0.3,0),1.8))\n",
    "                if bCount == 3:\n",
    "                    b.set_facecolor(scale_lightness((1,0.41,0),1.8))\n",
    "                    bCount = 0\n",
    "                b.set_ec('k')\n",
    "            for m in box['medians']:\n",
    "                m.set_lw(2)\n",
    "                m.set_color('k')\n",
    "            a.spines['top'].set_visible(False)\n",
    "            a.spines['right'].set_visible(False)\n",
    "            a.spines['bottom'].set_visible(False)\n",
    "            a.xaxis.set_ticks_position('none') \n",
    "            a.plot([1,1.95],[maxVal + valRange/5,maxVal+valRange/5],lw=1,color='k',zorder=2)\n",
    "            a.plot([2.05,2.95],[maxVal + valRange/5,maxVal+valRange/5],lw=1,color='k',zorder=2)\n",
    "#             a.plot([3.05,4],[maxVal + valRange/5,maxVal+valRange/5],lw=1,color='k',zorder=2)\n",
    "            a.plot([1,3],[maxVal + 2*(valRange/5),maxVal+2*(valRange/5)],lw=1,color='k',zorder=2)\n",
    "#             a.plot([2,4],[maxVal + 3*(valRange/5),maxVal+3*(valRange/5)],lw=1,color='k',zorder=2)\n",
    "#             a.plot([1,4],[maxVal + 4*(valRange/5),maxVal+4*(valRange/5)],lw=1,color='k',zorder=2)\n",
    "            a.scatter([1,1.95,2.05,2.95,1,3],[maxVal+valRange/5,maxVal+valRange/5,\n",
    "                                                              maxVal+valRange/5,maxVal+valRange/5,\n",
    "                                                              maxVal + 2*(valRange/5),maxVal+2*(valRange/5)],color=(0.8,0,0,1),s=30,zorder=3)\n",
    "        #pvals\n",
    "        ax2.text(1.5,maxVal + 1.1*(valRange/5),formatPval(dataList[0],dataList[1],len(featList)*3),fontsize=20,ha='center')\n",
    "        ax2.text(2.5,maxVal + 1.1*(valRange/5),formatPval(dataList[1],dataList[2],len(featList)*3),fontsize=20,ha='center')\n",
    "#         ax2.text(3.5,maxVal + 1.1*(valRange/5),formatPval(dataList[2],dataList[3],len(featList)*4),fontsize=20,ha='center')\n",
    "        ax2.text(2,maxVal + 2.1*(valRange/5),formatPval(dataList[0],dataList[2],len(featList)*3),fontsize=20,ha='center')\n",
    "#         ax2.text(3,maxVal + 3.1*(valRange/5),formatPval(dataList[1],dataList[3],len(featList)*4),fontsize=20,ha='center')\n",
    "#         ax2.text(2.5,maxVal + 4.1*(valRange/5),formatPval(dataList[0],dataList[3],len(featList)*4),fontsize=20,ha='center')\n",
    "       \n",
    "        ax.set_xlabel(namesDict[feature][0],fontsize=14,labelpad=14)\n",
    "        ax.yaxis.set_label_coords(-0.08, 1.05)\n",
    "        ax.set_ylim(ymin=0,ymax=max2)\n",
    "        ax.set_ylabel(namesDict[feature][1],fontsize=20)\n",
    "        ax.set_facecolor((0,0,0,0.05))\n",
    "        ax.grid(color='w',lw=2)\n",
    "        ax2.set_facecolor((0,0,0,0.05))\n",
    "        ax2.grid(color='w',lw=2)\n",
    "        ax2.vlines(x=1,color='w',lw=2,ymin=ax2.get_ylim()[0],ymax=ax2.get_ylim()[1])\n",
    "        ax2.vlines(x=2,color='w',lw=2,ymin=ax2.get_ylim()[0],ymax=ax2.get_ylim()[1])\n",
    "        ax2.vlines(x=3,color='w',lw=2,ymin=ax2.get_ylim()[0],ymax=ax2.get_ylim()[1])\n",
    "#         ax2.vlines(x=4,color='w',lw=2,ymin=ax2.get_ylim()[0],ymax=ax2.get_ylim()[1])\n",
    "        ax2.set_ylim(ymin=min2,ymax=maxVal+3*(valRange/5))\n",
    "#         ax2.tick_params(bottom=\"off\", labelbottom='off')\n",
    "        ax2.xaxis.set_visible(False)\n",
    "# data = np.linspace(1,100,num=30)\n",
    "# data2 = np.linspace(50,100,num=30)\n",
    "# data3 = np.linspace(1,75,num=30)\n",
    "    else:\n",
    "        dataList = [featDict[feature]['WGD'],featDict[feature]['SSD'],featDict[feature]['Singleton']]\n",
    "        maxVal = max([max(x) for x in dataList])\n",
    "        minVal = min([min(x) for x in dataList])\n",
    "        valRange = maxVal-minVal\n",
    "        box = ax.boxplot(dataList,labels=['WGD','SSD','Singleton'],patch_artist=True,flierprops={'ms':1})\n",
    "        ax.yaxis.set_tick_params(labelsize=14)\n",
    "        ax.xaxis.set_tick_params(labelsize=14)\n",
    "        bCount = 0\n",
    "        for b in box['boxes']:\n",
    "            bCount += 1\n",
    "            if bCount ==1:\n",
    "                #b.set_facecolor((0.9,0.2,0,0.7))\n",
    "                b.set_facecolor(scale_lightness((0.9,0.2,0),1.4))\n",
    "            if bCount == 2:\n",
    "                #b.set_facecolor((0.9,0.3,0,0.4))\n",
    "                b.set_facecolor(scale_lightness((0.9,0.3,0),1.8))\n",
    "            if bCount == 3:\n",
    "#                 b.set_facecolor((1,0.41,0,0.2))\n",
    "                b.set_facecolor(scale_lightness((1,0.41,0),1.8))\n",
    "                bCount = 0\n",
    "            b.set_ec('k')\n",
    "        for m in box['medians']:\n",
    "            m.set_lw(2)\n",
    "            m.set_color('k')\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['bottom'].set_visible(False)\n",
    "        ax.xaxis.set_ticks_position('none') \n",
    "        ax.plot([0.95,1.95],[maxVal + 1.1*(valRange/5),maxVal+1.1*(valRange/5)],lw=1,color='k',zorder=2)\n",
    "        ax.plot([2.05,3.05],[maxVal + 1.1*(valRange/5),maxVal+1.1*(valRange/5)],lw=1,color='k',zorder=2)\n",
    "#         ax.plot([3.05,4],[maxVal + valRange/5,maxVal+valRange/5],lw=1,color='k',zorder=2)\n",
    "        ax.plot([1,3],[maxVal + 2.2*(valRange/5),maxVal+2.2*(valRange/5)],lw=1,color='k',zorder=2)\n",
    "#         ax.plot([2,4],[maxVal + 3*(valRange/5),maxVal+3*(valRange/5)],lw=1,color='k',zorder=2)\n",
    "#         ax.plot([1,4],[maxVal + 4*(valRange/5),maxVal+4*(valRange/5)],lw=1,color='k',zorder=2)\n",
    "        ax.scatter([0.95,1.95,2.05,3.05,0.95,3.05],[maxVal+1.1*(valRange/5),maxVal+1.1*(valRange/5),\n",
    "                                                          maxVal+1.1*(valRange/5),maxVal+1.1*(valRange/5),\n",
    "                                                          maxVal + 2.2*(valRange/5),maxVal+2.2*(valRange/5)],color=(0.8,0,0,1),s=30,zorder=3)\n",
    "        #pvals\n",
    "        ax.text(1.45,maxVal + 1.3*(valRange/5),formatPval(dataList[0],dataList[1],len(featList)*3),fontsize=14,ha='center')\n",
    "        ax.text(2.55,maxVal + 1.3*(valRange/5),formatPval(dataList[1],dataList[2],len(featList)*3),fontsize=14,ha='center')\n",
    "#         ax.text(3.5,maxVal + 1.1*(valRange/5),formatPval(dataList[2],dataList[3],len(featList)*4),fontsize=14,ha='center')\n",
    "        ax.text(2,maxVal + 2.4*(valRange/5),formatPval(dataList[0],dataList[2],len(featList)*3),fontsize=14,ha='center')\n",
    "#         ax.text(3,maxVal + 3.1*(valRange/5),formatPval(dataList[1],dataList[3],len(featList)*4),fontsize=14,ha='center')\n",
    "#         ax.text(2.5,maxVal + 4.1*(valRange/5),formatPval(dataList[0],dataList[3],len(featList)*4),fontsize=14,ha='center')\n",
    "       \n",
    "        ax.set_xlabel(namesDict[feature][0],fontsize=16)\n",
    "        ax.set_ylabel(namesDict[feature][1],fontsize=16)\n",
    "        \n",
    "        ax.set_facecolor((0,0,0,0.05))\n",
    "        ax.grid(color='w',lw=2,zorder=0)\n",
    "        ax.set_ylim(ymax=maxVal+3*(valRange/5))\n",
    "        #     if feature == 'cdsLen':\n",
    "#         break\n",
    "# flatAx[-1].set_visible(False)\n",
    "plt.savefig('BOXPLOTS_PAIRWISE/final_constraint_no_mix_'+colUsed+'.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expression comparisons by tissue\n",
    "cursor.execute('SELECT id FROM gene_features WHERE dupCat_maj == \"WGD\"')\n",
    "wList = [x[0] for x in cursor.fetchall()]\n",
    "cursor.execute('SELECT id FROM gene_features WHERE dupCat_maj == \"SSD\"')\n",
    "sList = [x[0] for x in cursor.fetchall()]\n",
    "cursor.execute('SELECT id FROM gene_features WHERE dupCat_maj == \"Singleton (Vert)\" OR dupCat_maj == \"singleton\"')\n",
    "siList = [x[0] for x in cursor.fetchall()]\n",
    "\n",
    "expDictByTissueWGD = {}\n",
    "expDictByTissueSSD = {}\n",
    "expDictByTissueSing = {}\n",
    "for gene in exp_dict:\n",
    "    valList = exp_dict[gene]\n",
    "    for v in valList:\n",
    "        tissue,val = v\n",
    "        if gene in wList:\n",
    "            try:\n",
    "                expDictByTissueWGD[tissue].append(val)\n",
    "            except KeyError:\n",
    "                expDictByTissueWGD[tissue] = [val]\n",
    "        elif gene in sList:\n",
    "            try:\n",
    "                expDictByTissueSSD[tissue].append(val)\n",
    "            except KeyError:\n",
    "                expDictByTissueSSD[tissue] = [val]\n",
    "        elif gene in siList:\n",
    "            try:\n",
    "                expDictByTissueSing[tissue].append(val)\n",
    "            except KeyError:\n",
    "                expDictByTissueSing[tissue] = [val]\n",
    "fig, axes = plt.subplots(3,1,figsize=(17,9),gridspec_kw={'hspace':0.45})\n",
    "\n",
    "\n",
    "tissueList = [x for x in expDictByTissueWGD]\n",
    "# list1 = tissueList[312:320]\n",
    "# list2 = tissueList[320:328]\n",
    "# list3 = tissueList[328:336]\n",
    "\n",
    "list1 = ['10 week post conception, hindbrain',\n",
    "         '5 week post conception, kidney',\n",
    "         'Brain - Cerebellar Hemisphere',\n",
    "         'Whole Blood',\n",
    "         'Brain - Substantia nigra',\n",
    "         'Liver'] #largest and smallest differences\n",
    "\n",
    "list2 = ['7 week post conception, forebrain',\n",
    "         '9 week post conception, forebrain',\n",
    "         '10 week post conception, forebrain',\n",
    "         '13 week post conception, forebrain',\n",
    "         '16 week post conception, forebrain',\n",
    "         '18 week post conception, forebrain'] #changes over time in hindbrain development\n",
    "\n",
    "list3 = ['4 week post conception, liver',\n",
    "         '5 week post conception, liver',\n",
    "         '5 week post conception, liver',\n",
    "         '11 week post conception, liver',\n",
    "         '16 week post conception, liver',\n",
    "         '18 week post conception, liver'] #changes over time in liver development\n",
    "for tissues, ax in zip([list1,list2,list3],axes):\n",
    "    startBox = 0.5\n",
    "    for tissue in tissues:\n",
    "        ax.set_ylabel('Log(TPM)',fontsize=11)\n",
    "        bCount = 0\n",
    "#         wAdd = (min([x for x in expDictByTissueWGD[t] if x > 0]))/2\n",
    "#         sAdd = (min([x for x in expDictByTissueSSD[t] if x > 0]))/2\n",
    "#         siAdd = (min([x for x in expDictByTissueSing[t] if x > 0]))/2\n",
    "#         wVals = [log10(x) if x != 0 else log10(0.0001) for x in expDictByTissueWGD[tissue]]\n",
    "#         sVals = [log10(x) if x != 0 else log10(0.0001) for x in expDictByTissueSSD[tissue]]\n",
    "#         siVals = [log10(x) if x != 0 else log10(0.0001) for x in expDictByTissueSing[tissue]]\n",
    "        wVals = [log10(x) for x in expDictByTissueWGD[tissue] if x > 1]\n",
    "        sVals = [log10(x) for x in expDictByTissueSSD[tissue] if x > 1]\n",
    "        siVals = [log10(x) for x in expDictByTissueSing[tissue] if x > 1]\n",
    "        \n",
    "        totVals = []\n",
    "        totVals.extend(wVals)\n",
    "        totVals.extend(sVals)\n",
    "        totVals.extend(siVals)\n",
    "    #     positions= [startBox,startBox+0.25,startBox+0.5,startBox+0.75]\n",
    "    #     print(positions)\n",
    "        boxes = ax.boxplot([totVals,wVals,sVals,siVals],\n",
    "                           labels=['Total','WGD','SSD','Singleton'],\n",
    "                           positions=[startBox,startBox+0.5,startBox+1,startBox+1.5],\n",
    "                           patch_artist=True,flierprops={'ms':0.5})\n",
    "\n",
    "        for b in boxes['boxes']:\n",
    "            bCount += 1\n",
    "            if bCount == 2:\n",
    "                #b.set_facecolor((0.9,0.2,0,0.7))\n",
    "                b.set_facecolor(scale_lightness((0.9,0.2,0),1.4))\n",
    "            if bCount == 3:\n",
    "                #b.set_facecolor((0.9,0.3,0,0.4))\n",
    "                b.set_facecolor(scale_lightness((0.9,0.3,0),1.8))\n",
    "            if bCount == 1 or bCount == 4:\n",
    "    #                 b.set_facecolor((1,0.41,0,0.2))\n",
    "                b.set_facecolor(scale_lightness((1,0.41,0),1.8))\n",
    "#                 bCount = 0\n",
    "            b.set_ec('k')\n",
    "        for m in boxes['medians']:\n",
    "            m.set_lw(2)\n",
    "            m.set_color('k')\n",
    "        if ax == axes[0]:\n",
    "            ax.text(startBox+0.75,5.9,tissue.replace('post conception','p.c.').replace('week','weeks'),ha='center',fontsize=11.2)\n",
    "        elif ax == axes[1]:\n",
    "            ax.text(startBox+0.75,4.4,tissue.replace('post conception','p.c.').replace('week','weeks'),ha='center',fontsize=11.2)\n",
    "        else:\n",
    "            ax.text(startBox+0.75,5.6,tissue.replace('post conception','p.c.').replace('week','weeks'),ha='center',fontsize=11.2)\n",
    "        startBox = startBox + 2.5\n",
    "        ax.grid(color='w')\n",
    "        ax.set_fc((0,0,0,0.05))\n",
    "        if len(tissues) == 1:\n",
    "            ax.set_xlim(axes[0].get_xlim())\n",
    "#         ax.set_yticks(np.arange(-4,5,2))\n",
    "        ax.yaxis.set_tick_params(labelsize=11)\n",
    "        ax.xaxis.set_tick_params(labelsize=11.2,labelrotation=15)\n",
    "#         ax.set_xticklabels(['WGD','SSD','Singleton','Total'],fontsize=12,rotation=20,ha='right')\n",
    "plt.savefig('EXP_METH_BOXPLOTS/exp_finalRepresentativeSample.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GO enrichment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colUsed = 'dupCat_maj'\n",
    "cursor.execute('SELECT id FROM gene_features WHERE ' + colUsed + ' == \"WGD\"')\n",
    "wList = [x[0] for x in cursor.fetchall()]\n",
    "cursor.execute('SELECT id FROM gene_features WHERE ' + colUsed + ' == \"SSD\"')\n",
    "sList = [x[0] for x in cursor.fetchall()]\n",
    "cursor.execute('SELECT id FROM gene_features WHERE ' + colUsed + ' == \"singleton\" OR ' + colUsed + ' == \"Singleton (Vert)\"')\n",
    "siList = [x[0] for x in cursor.fetchall()]\n",
    "cursor.execute('SELECT id FROM gene_features WHERE ' + colUsed + ' == \"mix\"')\n",
    "miList = [x[0] for x in cursor.fetchall()]\n",
    "total = []\n",
    "for l in [wList, sList, siList, miList]:\n",
    "    total.extend(l)\n",
    "    \n",
    "gp = GProfiler()\n",
    "#default threshold of 0.05\n",
    "overWgdRes = gp.profile(query=wList, organism='hsapiens',significance_threshold_method='fdr',background=total)\n",
    "underWgdRes = gp.profile(query=wList, organism='hsapiens',significance_threshold_method='fdr',background=total,measure_underrepresentation=True)\n",
    "\n",
    "overWgdRes = [x for x in overWgdRes if 'GO' in x['source']]\n",
    "underWgdRes = [x for x in underWgdRes if 'GO' in x['source']]\n",
    "termNameOver = [(x['native'],x['name'],str(x['p_value'])) for x in overWgdRes]\n",
    "termNameUnder = [(x['native'],x['name'],str(x['p_value'])) for x in underWgdRes]\n",
    "wOver = [x['native'] for x in overWgdRes]\n",
    "wUnder = [x['native'] for x in underWgdRes]\n",
    "with open('overRepresentedWGD'+colUsed+'.txt','w') as file:\n",
    "    for x in termNameOver:\n",
    "        file.write('\\t'.join(x)+'\\n')\n",
    "with open('underRepresentedWGD'+colUsed+'.txt','w') as file:\n",
    "    for x in termNameUnder:\n",
    "        file.write('\\t'.join(x)+'\\n')\n",
    "        \n",
    "overSsdRes = gp.profile(query=sList, organism='hsapiens',significance_threshold_method='fdr',background=total)\n",
    "underSsdRes = gp.profile(query=sList, organism='hsapiens',significance_threshold_method='fdr',background=total,measure_underrepresentation=True)\n",
    "\n",
    "overSsdRes = [x for x in overSsdRes if 'GO' in x['source']]\n",
    "underSsdRes = [x for x in underSsdRes if 'GO' in x['source']]\n",
    "termNameOver = [(x['native'],x['name'],str(x['p_value'])) for x in overSsdRes]\n",
    "termNameUnder = [(x['native'],x['name'],str(x['p_value'])) for x in underSsdRes]\n",
    "sOver = [x['native'] for x in overSsdRes]\n",
    "sUnder = [x['native'] for x in underSsdRes]\n",
    "with open('overRepresentedSSD'+colUsed+'.txt','w') as file:\n",
    "    for x in termNameOver:\n",
    "        file.write('\\t'.join(x)+'\\n')\n",
    "with open('underRepresentedSSD'+colUsed+'.txt','w') as file:\n",
    "    for x in termNameUnder:\n",
    "        file.write('\\t'.join(x)+'\\n')\n",
    "        \n",
    "overSingRes = gp.profile(query=siList, organism='hsapiens',significance_threshold_method='fdr',background=total)\n",
    "underSingRes = gp.profile(query=siList, organism='hsapiens',significance_threshold_method='fdr',background=total,measure_underrepresentation=True)\n",
    "\n",
    "overSingRes = [x for x in overSingRes if 'GO' in x['source']]\n",
    "underSingRes = [x for x in underSingRes if 'GO' in x['source']]\n",
    "termNameOver = [(x['native'],x['name'],str(x['p_value'])) for x in overSingRes]\n",
    "termNameUnder = [(x['native'],x['name'],str(x['p_value'])) for x in underSingRes]\n",
    "siOver = [x['native'] for x in overSingRes]\n",
    "siUnder = [x['native'] for x in underSingRes]\n",
    "with open('overRepresentedSingleton'+colUsed+'.txt','w') as file:\n",
    "    for x in termNameOver:\n",
    "        file.write('\\t'.join(x)+'\\n')\n",
    "with open('underRepresentedSingleton'+colUsed+'.txt','w') as file:\n",
    "    for x in termNameUnder:\n",
    "        file.write('\\t'.join(x)+'\\n')\n",
    "        \n",
    "overMixRes = gp.profile(query=miList, organism='hsapiens',significance_threshold_method='fdr',background=total)\n",
    "underMixRes = gp.profile(query=miList, organism='hsapiens',significance_threshold_method='fdr',background=total,measure_underrepresentation=True)\n",
    "\n",
    "overMixRes = [x for x in overMixRes if 'GO' in x['source']]\n",
    "underMixRes = [x for x in underMixRes if 'GO' in x['source']]\n",
    "termNameOver = [(x['native'],x['name'],str(x['p_value'])) for x in overMixRes]\n",
    "termNameUnder = [(x['native'],x['name'],str(x['p_value'])) for x in underMixRes]\n",
    "miOver = [x['native'] for x in overMixRes]\n",
    "miUnder = [x['native'] for x in underMixRes]\n",
    "with open('overRepresentedMix'+colUsed+'.txt','w') as file:\n",
    "    for x in termNameOver:\n",
    "        file.write('\\t'.join(x)+'\\n')\n",
    "with open('underRepresentedMix'+colUsed+'.txt','w') as file:\n",
    "    for x in termNameUnder:\n",
    "        file.write('\\t'.join(x)+'\\n')\n",
    "catContent = {'WGD enriched':wOver,'SSD enriched': sOver, 'Singleton enriched':siOver, 'Mixed enriched':miOver,\n",
    "             'WGD depleted':wUnder, 'SSD depleted':sUnder, 'Singleton depleted':siUnder, 'Mixed depleted':miUnder}\n",
    "uplot(from_contents(catContent),sort_by='cardinality',show_counts = True)\n",
    "plt.savefig('UPSET_PLOTS/upsetPlot_go_'+colUsed+'.svg',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catContent = {'WGD enriched':wOver,'SSD enriched': sOver, 'Singleton enriched':siOver,\n",
    "             'WGD depleted':wUnder, 'SSD depleted':sUnder, 'Singleton depleted':siUnder}\n",
    "plot = uplot(from_contents(catContent),sort_by='cardinality',show_counts = True)\n",
    "plot['matrix'].set_yticklabels(plot['matrix'].get_yticklabels(),fontsize=12)\n",
    "# labs = plot['intersections'].get_ymajorticklabels()\n",
    "plot['intersections'].set_yticklabels(labs,fontsize=12)\n",
    "plot['intersections'].set_ylabel('Intersection size',fontsize=12)\n",
    "box = plot['totals'].get_position()\n",
    "box.x0 = box.x0 - 0.05\n",
    "box.x1 = box.x1 -0.05\n",
    "plot['totals'].set_position(box)\n",
    "for t in plot['totals'].texts:\n",
    "    t.set_fontsize(12)\n",
    "for t in plot['intersections'].texts:\n",
    "    t.set_fontsize(11)\n",
    "plt.savefig('UPSET_PLOTS/upsetPlot_go_WGD_SSD_Sing'+colUsed+'.svg',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catContent = {'WGD enriched':wOver,'Singleton enriched':siOver,\n",
    "             'WGD depleted':wUnder,'Singleton depleted':siUnder}\n",
    "plot = uplot(from_contents(catContent),sort_by='cardinality',show_counts = True)\n",
    "plot['matrix'].set_yticklabels(plot['matrix'].get_yticklabels(),fontsize=12)\n",
    "# labs = plot['intersections'].get_ymajorticklabels()\n",
    "plot['intersections'].set_yticklabels(labs,fontsize=12)\n",
    "plot['intersections'].set_ylabel('Intersection size',fontsize=12)\n",
    "box = plot['totals'].get_position()\n",
    "box.x0 = box.x0 - 0.05\n",
    "box.x1 = box.x1 -0.05\n",
    "plot['totals'].set_position(box)\n",
    "for t in plot['totals'].texts:\n",
    "    t.set_fontsize(12)\n",
    "for t in plot['intersections'].texts:\n",
    "    t.set_fontsize(12)\n",
    "plt.savefig('UPSET_PLOTS/upsetPlot_go_WGD_Sing'+colUsed+'.svg',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catContent = {'SSD enriched':sOver,'Singleton enriched':siOver,\n",
    "             'SSD depleted':sUnder,'Singleton depleted':siUnder}\n",
    "plot = uplot(from_contents(catContent),sort_by='cardinality',show_counts = True)\n",
    "plot['matrix'].set_yticklabels(plot['matrix'].get_yticklabels(),fontsize=12)\n",
    "# labs = plot['intersections'].get_ymajorticklabels()\n",
    "plot['intersections'].set_yticklabels(labs,fontsize=12)\n",
    "plot['intersections'].set_ylabel('Intersection size',fontsize=12)\n",
    "box = plot['totals'].get_position()\n",
    "box.x0 = box.x0 - 0.05\n",
    "box.x1 = box.x1 -0.05\n",
    "plot['totals'].set_position(box)\n",
    "for t in plot['totals'].texts:\n",
    "    t.set_fontsize(12)\n",
    "for t in plot['intersections'].texts:\n",
    "    t.set_fontsize(11)\n",
    "plt.savefig('UPSET_PLOTS/upsetPlot_go_SSD_Sing'+colUsed+'.svg',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catContent = {'WGD enriched':wOver,'SSD enriched': sOver,\n",
    "             'WGD depleted':wUnder, 'SSD depleted':sUnder,}\n",
    "plot = uplot(from_contents(catContent),sort_by='cardinality',show_counts = True)\n",
    "plot['matrix'].set_yticklabels(plot['matrix'].get_yticklabels(),fontsize=12)\n",
    "# labs = plot['intersections'].get_ymajorticklabels()\n",
    "plot['intersections'].set_yticklabels(labs,fontsize=12)\n",
    "plot['intersections'].set_ylabel('Intersection size',fontsize=12)\n",
    "box = plot['totals'].get_position()\n",
    "box.x0 = box.x0 - 0.05\n",
    "box.x1 = box.x1 -0.05\n",
    "plot['totals'].set_position(box)\n",
    "for t in plot['totals'].texts:\n",
    "    t.set_fontsize(12)\n",
    "for t in plot['intersections'].texts:\n",
    "    t.set_fontsize(12)\n",
    "plt.savefig('UPSET_PLOTS/upsetPlot_go_WGD_SSD'+colUsed+'.svg',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
